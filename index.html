<!DOCTYPE html>
<html lang="en">

<head>
<meta charset="utf-8">
<!--[if IE]><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><![endif]-->
<title>Haggai's Homepage</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<!--
<meta name="description" content="Haggai's web page" />
<meta name="author" content="tamarillo" />
-->
<!-- favicons -->
<!-- <link rel="shortcut icon" href="images/templatemo_favicon.ico"> -->
<!-- bootstrap core CSS -->
<link href="css/bootstrap.min.css" rel="stylesheet" />
<!-- fancybox CSS -->
<link href="css/jquery.lightbox.css" rel="stylesheet" />
<!-- flex slider CSS -->
<link href="css/flexslider.css" rel="stylesheet" />
<!-- custom styles for this template -->
<link href="css/templatemo_style.css" rel="stylesheet" />
<!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
<script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
<![endif]-->
</head>
<body>
<header>
    <div class="container">
        <div class="row">

            <div class="col-md-3 hidden-xs"></div>
            <div class="col-xs-3 col-xs-offset-20 visible-xs">
                <a href="#" id="mobile_menu"><span class="glyphicon glyphicon-align-justify"></span></a>
            </div>
            <div class="col-xs-24 visible-xs" id="mobile_menu_list">
                <ul>
					<li><a href="#templatemo_about">About</a></li>
                    <!-- <li><a href="#templatemo_slideshow">Slideshow</a></li> -->
                    <li><a href="#templatemo_publications">Publications</a></li>
                    <li><a href="/blog/" onclick="location.replace('https://haggaim.github.io/blog'),'_top'">Blog</a></li>
                </ul>
            </div>
            <div class="col-md-16 col-sm-18 hidden-xs" id="templatemo-nav-bar">
                <ul class="nav navbar-right">
					<li><a href="#templatemo_about">About</a></li>
                    <!-- <li><a href="#templatemo_slideshow">Slideshow</a></li> -->
                    <li><a href="#templatemo_publications">Publications</a></li>
                </ul>
            </div>
        </div>
    </div>
</header><!-- end of templatemo_header -->

<section id="templatemo_about">
    <div class="container">
        <div class="row">
            <div class="col-md-2"></div>
            <div id="my_photo" class="col-md-4 col-sm-7 col-xs-24">
                <img src="images/haggai017.jpg" alt="image 1"/>
            </div>
            <div class="col-md-1"></div>
            <div class="col-md-16">
                <h2>Haggai Maron</h2>
				<p>
          I am an Assistant Professor and the Robert J. Shillman Fellow at the <a href="https://vee.technion.ac.il/"> Faculty of Electrical and Computer Engineering at the Technion</a> and a senior research scientist at <a href="https://www.nvidia.com/en-us/research/">NVIDIA Research</a> at <a href="https://research.nvidia.com/labs/par/">NVIDIA's lab in Tel Aviv</a>.
          My primary research interest is in machine learning, with a focus on deep learning for structured data. Specifically, I study how to apply deep learning techniques to sets, graphs, point clouds, surfaces, weight spaces and other mathematical objects that have an inherent symmetry structure. My goal is twofold: first, to understand and design deep learning architectures from a theoretical perspective, for example, by analyzing their expressive power; and second, to demonstrate their practical effectiveness on real-world problems involving structured data.
          I completed my Ph.D. in 2019 at the Weizmann Institute of Science under the supervision of <a href="http://www.wisdom.weizmann.ac.il/~ylipman/">Prof. Yaron Lipman</a>. </br>
          <!--I serve as a reviewer for NeurIPS, ICML, ICCV, SIGGRAPH, SIGGRAPH Asia and ACM TOG.<br>-->
          <!--<My CV can be found <a href="cv.pdf">here</a>.

          <h4>Prospective students:</h4>
          I am seeking highly motivated Ph.D. students to join my new lab at the Technion. My research combines machine learning, and some aspects of algebra and graph theory, so knowledge and/or interest in these fields are a big plus.
          Coding skills are also required. -->

          You can get an idea of what I am working on by taking a look at these three recent talks I gave:
          <ul>
            <li><a href='https://www.youtube.com/watch?v=B9xFem6_ckQ&t=8182s'>Equivaraint architectures for learning in deep weight spaces </a></li>

          <li><a href='https://library.cirm-math.fr/Record.htm?idlist=1&record=19280739124910089119'>Subgraph-based networks for expressive, efficient, and domain-independent graph learning </a></li>

          <li> <a href='https://www.youtube.com/watch?v=k3E3XyMtQcA&list=PL7VfmMOOwNlJ5PndlhiMwjvqDTA6m1Z9i&index=2&t=120s'>Leveraging Permutation Group Symmetries for Equivariant Neural Networks </a></li>

          </ul>
        You can also listen to a recent <a href='https://explainable.podbean.com/e/%d7%a8%d7%a9%d7%aa%d7%95%d7%aa%d7%a0%d7%95%d7%99%d7%a8%d7%95%d7%a0%d7%99%d7%9d%d7%a2%d7%9c-%d7%92%d7%a8%d7%a4%d7%99%d7%9d-%d7%a2/?fbclid=IwAR2oz8wjYc0qSwIt2clNWrFeMzNJMvV5Ycop166V6p5ZSB0JYeHF8sEkghg
'>podcast </a> with me on graph neural networks (hebrew).
          				<br>
                </p>
				<p>
				<b>Email:</b> hmaron (at) nvidia.com, <a href="https://scholar.google.co.il/citations?user=4v8uJrIAAAAJ">Google scholar page</a>, <a href="https://github.com/Haggaim">GitHub page</a><br>
        <p>
            <h4>Group</h4>
            <b>Current Group Members:</b>
            <span class="member"><a href="https://noired.github.io/">Fabrizio Frasca</a> (Postdoc, 2024-today),</span>
            <span class="member"><a href="https://scholar.google.com/citations?user=INF2QpcAAAAJ&hl=iw">Yam Eitan</a> (PhD, 2024 - today),</span>
            <span class="member"><a href="https://barsguy.github.io/">Guy Bar-Shalom</a> (PhD, 2023 - today, joint supervision with <a href="https://csaws.cs.technion.ac.il/~rani/">Ran El-Yaniv</a>),</span>
            <span class="member"><a href="https://scholar.google.co.il/citations?user=iS3AYtAAAAAJ&hl=iw">Matan Ostrovsky</a> (PhD, 2023 - today),</span>
            <span class="member"><a href="https://yoavgelberg.github.io/">Yoav Gelberg</a> (PhD, 2024-today, joint supervision with <a href="https://www.cs.ox.ac.uk/people/michael.bronstein/">Michael Bronstein</a>),</span>
            <span class="member">Ran Elbaz (Msc, 2023-today),</span>
            <span class="member">Yaniv Galron (MSc, 2023-today, joint supervision with <a href="https://www.cs.bgu.ac.il/~erant/">Eran Treister</a>)</span><br>
            <b>Past Group Members:</b>
            <span class="member">Yuval Aidan (MSc, 2023-2025, joint supervision with <a href="https://webee.technion.ac.il/Sites/People/ayellet/">Ayellet Tal</a>).</span><br>
            <span class="member">Edan Kinderman (MSc, 2023-2025, joint supervision with <a href="https://soudry.github.io/">Daniel Soudry</a>),</span>
            <span class="member">Ofir Haim (MSc, 2023-2025, joint supervision with <a href="https://webee.technion.ac.il/Sites/People/shie/">Shie Mannor</a>)</span><br>
            <b>Close student / postdoc collaborators:</b>
            <span class="member"><a href="https://sites.google.com/berkeley.edu/moeputterman/home?authuser=0">Theo (Moe) Putterman</a> (UC Berkeley, 2023-today),</span>
            <span class="member"><a href="https://beabevi.github.io/">Beatrice Bevilacqua</a> (PhD Candidate, Purdue University, 2021-today),</span>
            <span class="member"><a href="https://cptq.github.io/about/">Derek Lim</a> (PhD student, MIT CSAIL, 2021-today),</span>
            <span class="member"><a href="https://scholar.google.com/citations?user=44LKqBsAAAAJ&hl=iw">Moshe Eliasof</a> (Postdoc, University of Cambridge, 2022-today),</span>
            <span class="member"><a href="https://avivnavon.github.io/">Aviv Navon</a> (Aiola, 2021-today),</span>
            <span class="member"><a href="https://avivsham.github.io/">Aviv Shamsian</a> (Aiola, 2022-today).</span>
        </p>
                <p>
                <h4>News</h4>
                <ul>
                <li> 3 papers accepted to ICLR 2025.</li>
                <li> 4 papers accepted to NeurIPS 2024.</li>
                <li> Proud to be the recipient of the <a href='https://che.org.il/en/scholarships-integration-outstanding-faculty/'>Alon scholarship for the Integration of Outstanding Faculty</a>.
                <li> 5 papers accepted to ICML 2024.</li>
                <li> See my recent talk on <a href='https://www.youtube.com/watch?v=B9xFem6_ckQ&t=8182s'>Equivaraint architectures for learning in deep weight spaces </a>. </li>
                <li> A new <a href='https://developer.nvidia.com/blog/designing-deep-networks-to-process-other-deep-networks/'> blog post on Equivaraint architectures for learning in deep weight spaces </a>. </li>
                <li> I will serve as an area chair at NeurIPS 2023.</li>
                <li> See our recent tutorial on <a href='https://www.youtube.com/watch?v=ASQYjbUBYzs'>Exploring the practical and theoretical landscape of expressive graph neural networks </a> given at the <a href='https://logconference.org/'> Learning on Graphs Conference </a>. With With Fabrizio Frasca and Beatrice Bevilacqua. </li>
                <li> A <a href="https://towardsdatascience.com/using-subgraphs-for-more-expressive-gnns-8d06418d5ab"> new blog post on Subggraph GNNs</a> on Towards Data Science.</li>
                <li>Our ICML 2020 paper <a href="https://arxiv.org/pdf/2002.08599">On Learning Sets of Symmetric Elements</a> received the <b>Outstanding paper award</b> (best paper award). See this <a href="https://aihub.org/2020/08/20/interview-with-haggai-maron-icml2020-award-winner/">interview</a> for more details.</li>

                </ul>
                </p>

                <p>
                <h4>Teaching</h4>
                <ul>
                <li>2025/Spring (Technion):   Introduction to Machine Learning </li>
                <li>2025/Spring (Technion):   Deep Learning and groups </li>
                <li>2024/winter (Technion):   Topics in learning on graphs </li>
                <li>2024/Spring (Technion):   Deep Learning and groups </li>
                <li>2023/winter (Technion):   Topics in learning on graphs </li>
                <li>2019/spring (WIS):   Geometric and Algebraic Methods in Deep Learning </li>
                <li>2018/winter (WIS):   Geometry and Deep Learning </li>
                </ul>
                </p>



            </div>
            <center>
            <a class="twitter-timeline" data-width="1000" data-height="400" href="https://twitter.com/HaggaiMaron?ref_src=twsrc%5Etfw">Tweets by HaggaiMaron</a> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
          </center>

        </div><!-- end of row -->
    </div>

</section><!-- end of templatemo_about -->





<section id="templatemo_publications">
    <div class="container">
		<hr>
        <div class="row">
            <h1>Publications</h1>
        </div>
      </div>

      <!--Open problems -->
         <div class="row" id="templatemo_publications_LargeScaleBD">
             <div class="col-md-1"></div>
             <div class="col-md-5 col-sm-7 col-xs-24">
                 <img src="projects/TDL/rep.png" width="450" " alt="">
             </div>
             <div class="col-md-1"></div>
             <div class="col-md-16">
                 <h2>Topological Blind Spots: Understanding and Extending Topological Deep Learning Through the Lens of Expressivity</h2>
                 <p>
                   Yam Eitan, Yoav Gelberg, Guy Bar-Shalom, Fabrizio Frasca, Michael Bronstein, Haggai Maron <br>

                   <i>International Conference on Learning Representations (ICLR) 2025</i> <br>
                   <p style="color:red;">Oral Presentation</p>

                 <a class="btn btn-default abstract" ptitle="Topological deep learning (TDL) facilitates learning from data represented by topological structures. The primary model utilized in this setting is higher-order message-passing (HOMP), which extends traditional graph message-passing neural networks (MPNN) to diverse topological domains. Given the significant expressivity limitations of MPNNs, our paper aims to explore both the strengths and weaknesses of HOMP's expressive power and subsequently design novel architectures to address these limitations. We approach this from several perspectives: First, we demonstrate HOMP's inability to distinguish between topological objects based on fundamental topological and metric properties such as diameter, orientability, planarity, and homology. Second, we show HOMP's limitations in fully leveraging the topological structure of objects constructed using common lifting and pooling operators on graphs. Finally, we compare HOMP's expressive power to hypergraph networks, which are the most extensively studied TDL methods. We then develop two new classes of TDL models: multi-cellular networks (MCN) and scalable multi-cellular networks (SMCN). These models draw inspiration from expressive graph architectures. While MCN can reach full expressivity but is highly unscalable, SMCN offers a more scalable alternative that still mitigates many of HOMP's expressivity limitations. Finally, we construct a synthetic dataset, where TDL models are tasked with separating pairs of topological objects based on basic topological properties. We demonstrate that while HOMP is unable to distinguish between any of the pairs in the dataset, SMCN successfully distinguishes all pairs, empirically validating our theoretical findings. Our work opens a new design space and new opportunities for TDL, paving the way for more expressive and versatile models."> Abstract</a>
                 <a href="https://openreview.net/forum?id=EzjsoomYEb" class="btn btn-default">Paper </a>

             </div>
      </div><!-- end of row -->


      <!--Open problems -->
         <div class="row" id="templatemo_publications_LargeScaleBD">
             <div class="col-md-1"></div>
             <div class="col-md-5 col-sm-7 col-xs-24">
                 <img src="projects/spectral_homom/rep.png" width="450" " alt="">
             </div>
             <div class="col-md-1"></div>
             <div class="col-md-16">
                 <h2>Homomorphism Expressivity of Spectral Invariant Graph Neural Networks</h2>
                 <p>
                   Jingchu Gai, Yiheng Du, Bohang Zhang, Haggai Maron, Liwei Wang <br>

                   <i>International Conference on Learning Representations (ICLR) 2025</i> <br>
                   <p style="color:red;">Oral Presentation</p>

                 <a class="btn btn-default abstract" ptitle="Graph spectra are an important class of structural features on graphs that have shown promising results in enhancing Graph Neural Networks (GNNs). Despite their widespread practical use, the theoretical understanding of the power of spectral invariants --- particularly their contribution to GNNs --- remains incomplete. In this paper, we address this fundamental question through the lens of homomorphism expressivity, providing a comprehensive and quantitative analysis of the expressive power of spectral invariants. Specifically, we prove that spectral invariant GNNs can homomorphism-count exactly a class of specific tree-like graphs which we refer to as \emph{parallel trees}. We highlight the significance of this result in various contexts, including establishing a quantitative expressiveness hierarchy across different architectural variants, offering insights into the impact of GNN depth, and understanding the subgraph counting capabilities of spectral invariant GNNs. In particular, our results significantly extend \citet{arvind2024hierarchy} and settle their open questions. Finally, we generalize our analysis to higher-order GNNs and answer an open question raised by \citet{zhang2024expressive}."> Abstract</a>
                 <a href="https://openreview.net/forum?id=rdv6yeMFpn" class="btn btn-default">Paper </a>

             </div>
      </div><!-- end of row -->








      <!--Open problems -->
         <div class="row" id="templatemo_publications_LargeScaleBD">
             <div class="col-md-1"></div>
             <div class="col-md-5 col-sm-7 col-xs-24">
                 <img src="projects/lightning-fast/rep.png" width="450" " alt="">
             </div>
             <div class="col-md-1"></div>
             <div class="col-md-16">
                 <h2>Lightning-Fast Image Inversion and Editing for Text-to-Image Diffusion Models</h2>
                 <p>
                   Dvir Samuel, Barak Meiri, Haggai Maron, Yoad Tewel, Nir Darshan, Shai Avidan, Gal Chechik, Rami Ben-Ari <br>

                   <i>International Conference on Learning Representations (ICLR) 2025</i> <br>
                 <a class="btn btn-default abstract" ptitle="Diffusion inversion is the problem of taking an image and a text prompt that describes it and finding a noise latent that would generate the exact same image. Most current deterministic inversion techniques operate by approximately solving an implicit equation and may converge slowly or yield poor reconstructed images. We formulate the problem by finding the roots of an implicit equation and design a method to solve it efficiently. Our solution is based on Newton-Raphson (NR), a well-known technique in numerical analysis. We show that a vanilla application of NR is computationally infeasible while naively transforming it to a computationally tractable alternative tends to converge to out-of-distribution solutions, resulting poor reconstruction and editing. We therefore derive an efficient guided formulation that fastly converges and provides high-quality reconstructions and editing. We showcase our method on real image editing with three popular open-sourced diffusion models: Stable Diffusion, SDXL-Turbo and Flux with different deterministic schedulers. Our solution, Guided Newton-Raphson Inversion, inverts an image within 0.4 sec (on an A100 GPU) for few-step models (SDXL-Turbo and Flux.1), opening the door for interactive image editing. We further show improved results in image interpolation and generation of rare objects."> Abstract</a>
                 <a href="https://openreview.net/forum?id=t9l63huPRt" class="btn btn-default">Paper </a>

             </div>
      </div><!-- end of row -->





      <!--Open problems -->
         <div class="row" id="templatemo_publications_LargeScaleBD">
             <div class="col-md-1"></div>
             <div class="col-md-5 col-sm-7 col-xs-24">
                 <img src="projects/coarsening/rep.png" width="450" " alt="">
             </div>
             <div class="col-md-1"></div>
             <div class="col-md-16">
                 <h2>A Flexible, Equivariant Framework for Subgraph GNNs via Graph Products and Graph Coarsening</h2>
                 <p>
                   Guy Bar-Shalom, Yam Eitan, Fabrizio Frasca, Haggai Maron <br>

                   <i>38th Annual Conference on Neural Information Processing Systems (NeurIPS 2024)  </i> <br> </p>
                   <i>(A shorter version also appeared in the Symmetry and Geometry in Neural Representations
 Workshop @ NeurIPS 2024</i> winning the <span style="color:red;">best paper award</span>)</p>

                 <a class="btn btn-default abstract" ptitle="Subgraph Graph Neural Networks (Subgraph GNNs) enhance the expressivity of message-passing GNNs by representing graphs as sets of subgraphs. They have shown impressive performance on several tasks, but their complexity limits applications to larger graphs. Previous approaches suggested processing only subsets of subgraphs, selected either randomly or via learnable sampling. However, they make suboptimal subgraph selections or can only cope with very small subset sizes, inevitably incurring performance degradation. This paper introduces a new Subgraph GNNs framework to address these issues. We employ a graph coarsening function to cluster nodes into super-nodes with induced connectivity. The product between the coarsened and the original graph reveals an implicit structure whereby subgraphs are associated with specific sets of nodes. By running generalized message-passing on such graph product, our method effectively implements an efficient, yet powerful Subgraph GNN. Controlling the coarsening function enables meaningful selection of any number of subgraphs while, contrary to previous methods, being fully compatible with standard training techniques. Notably, we discover that the resulting node feature tensor exhibits new, unexplored permutation symmetries. We leverage this structure, characterize the associated linear equivariant layers and incorporate them into the layers of our Subgraph GNN architecture. Extensive experiments on multiple graph learning benchmarks demonstrate that our method is significantly more flexible than previous approaches, as it can seamlessly handle any number of subgraphs, while consistently outperforming baseline approaches."> Abstract</a>
                 <a href="https://arxiv.org/abs/2406.09291" class="btn btn-default">Paper </a>

             </div>
      </div><!-- end of row -->


      <!--Open problems -->
         <div class="row" id="templatemo_publications_LargeScaleBD">
             <div class="col-md-1"></div>
             <div class="col-md-5 col-sm-7 col-xs-24">
                 <img src="projects/4d/rep.png" width="450" " alt="">
             </div>
             <div class="col-md-1"></div>
             <div class="col-md-16">
                 <h2>Fast Encoder-Based 3D from Casual Videos via Point Track Processing</h2>
                 <p>
                   Yoni Kasten, Wuyue Lu, Haggai Maron <br>

                   <i>38th Annual Conference on Neural Information Processing Systems (NeurIPS 2024)  </i> <br> </p>
                 <a class="btn btn-default abstract" ptitle="This paper addresses the long-standing challenge of reconstructing 3D structures from videos with dynamic content. Current approaches to this problem were not designed to operate on casual videos recorded by standard cameras or require a long optimization time.
Aiming to significantly improve the efficiency of previous approaches, we present TracksTo4D, a learning-based approach that enables inferring 3D structure and camera positions from dynamic content originating from casual videos using a single efficient feed-forward pass. To achieve this, we propose operating directly over 2D point tracks as input and designing an architecture tailored for processing 2D point tracks. Our proposed architecture is designed with two key principles in mind: (1) it takes into account the inherent symmetries present in the input point tracks data, and (2) it assumes that the movement patterns can be effectively represented using a low-rank approximation. TracksTo4D is trained in an unsupervised way on a dataset of casual videos utilizing only the 2D point tracks extracted from the videos, without any 3D supervision. Our experiments show that TracksTo4D can reconstruct a temporal point cloud and camera positions of the underlying video with accuracy comparable to state-of-the-art methods, while drastically reducing runtime by up to 95\%. We further show that TracksTo4D generalizes well to unseen videos of unseen semantic categories at inference time."> Abstract</a>
                 <a href="https://arxiv.org/abs/2404.07097" class="btn btn-default">Paper </a>

             </div>
      </div><!-- end of row -->


      <!--Open problems -->
         <div class="row" id="templatemo_publications_LargeScaleBD">
             <div class="col-md-1"></div>
             <div class="col-md-5 col-sm-7 col-xs-24">
                 <img src="projects/granola/rep.png" width="450" " alt="">
             </div>
             <div class="col-md-1"></div>
             <div class="col-md-16">
                 <h2>GRANOLA: Adaptive Normalization for Graph Neural Networks</h2>
                 <p>
                   Moshe Eliasof, Beatrice Bevilacqua, Carola-Bibiane Schönlieb, Haggai Maron <br>

                   <i>38th Annual Conference on Neural Information Processing Systems (NeurIPS 2024)  </i> <br> </p>
                 <a class="btn btn-default abstract" ptitle="In recent years, significant efforts have been made to refine the design of Graph Neural Network (GNN) layers, aiming to overcome diverse challenges, such as limited expressive power and oversmoothing. Despite their widespread adoption, the incorporation of off-the-shelf normalization layers like BatchNorm or InstanceNorm within a GNN architecture may not effectively capture the unique characteristics of graph-structured data, potentially reducing the expressive power of the overall architecture. Moreover, existing graph-specific normalization layers often struggle to offer substantial and consistent benefits. In this paper, we propose GRANOLA, a novel graph-adaptive normalization layer. Unlike existing normalization layers, GRANOLA normalizes node features by adapting to the specific characteristics of the graph, particularly by generating expressive representations of its neighborhood structure, obtained by leveraging the propagation of Random Node Features (RNF) in the graph. We present theoretical results that support our design choices. Our extensive empirical evaluation of various graph benchmarks underscores the superior performance of GRANOLA over existing normalization techniques. Furthermore, GRANOLA emerges as the top-performing method among all baselines within the same time complexity of Message Passing Neural Networks (MPNNs)."> Abstract</a>
                 <a href="https://arxiv.org/abs/2404.13344" class="btn btn-default">Paper </a>

             </div>
      </div><!-- end of row -->






      <!--Open problems -->
         <div class="row" id="templatemo_publications_LargeScaleBD">
             <div class="col-md-1"></div>
             <div class="col-md-5 col-sm-7 col-xs-24">
                 <img src="projects/asymetric_networks/rep.png" width="450" " alt="">
             </div>
             <div class="col-md-1"></div>
             <div class="col-md-16">
                 <h2>The Empirical Impact of Neural Parameter Symmetries, or Lack Thereof</h2>
                 <p>
                   Derek Lim*, Theo (Moe) Putterman*, Robin Walters, Haggai Maron, Stefanie Jegelka<br>
                   <i>38th Annual Conference on Neural Information Processing Systems (NeurIPS 2024)  </i> <br>

                 <i>(A shorter version also appeared in HiLD 2024: 2nd Workshop on High-dimensional Learning Dynamics @ ICML 2024</i> winning the <span style="color:red;">best paper award</span>)</p>

                 <a class="btn btn-default abstract" ptitle="Many algorithms and observed phenomena in deep learning appear to be affected by parameter symmetries — transformations of neural network parameters that do not change the underlying
      neural network function. These include linear mode connectivity, model merging, Bayesian neural network inference, metanetworks, and several other characteristics of optimization or loss-landscapes.
      In this work, we empirically investigate the impact of neural parameter symmetries by introducing new neural network architectures that have reduced parameter space symmetries. We develop
      two methods, with some provable guarantees, of modifying standard neural networks to reduce parameter space symmetries. With these new methods, we conduct a comprehensive experimental
      study consisting of multiple tasks aimed at assessing the effect of removing parameter symmetries. Our experiments reveal several interesting observations on the empirical impact of parameter
      symmetries; for instance, we observe linear mode connectivity and monotonic linear interpolation in our networks, without any alignment of weight spaces."> Abstract</a>
                 <a href="https://openreview.net/pdf?id=gkrynRGiOi" class="btn btn-default">Paper (Workshop version) </a>
                 <a href="https://arxiv.org/abs/2405.20231" class="btn btn-default">Paper (Full version) </a>

             </div>
      </div><!-- end of row -->



      <!--Open problems -->
         <div class="row" id="templatemo_publications_LargeScaleBD">
             <div class="col-md-1"></div>
             <div class="col-md-5 col-sm-7 col-xs-24">
                 <img src="projects/future_graph_learning/rep.png" width="400" " alt="">
             </div>
             <div class="col-md-1"></div>
             <div class="col-md-16">
                 <h2>Future Directions in Foundations of Graph Machine Learning</h2>
                 <p>
                   Christopher Morris, Nadav Dym, Haggai Maron, İsmail İlkan Ceylan, Fabrizio Frasca, Ron Levie, Derek Lim, Michael Bronstein, Martin Grohe, Stefanie Jegelka <br>
                   <i>International Conference on Machine Learning (ICML) 2024</i> <br>

                 </p>
                 <a class="btn btn-default abstract" ptitle="Machine learning on graphs, especially using graph neural networks (GNNs), has seen a surge in interest due to the wide availability of graph data across a broad spectrum of disciplines, from life to social and engineering sciences. Despite their practical success, our theoretical understanding of the properties of GNNs remains highly incomplete. Recent theoretical advancements primarily focus on elucidating the coarse-grained expressive power of GNNs, predominantly employing combinatorial techniques. However, these studies do not perfectly align with practice, particularly in understanding the generalization behavior of GNNs when trained with stochastic first-order optimization techniques. In this position paper, we argue that the graph machine learning community needs to shift its attention to developing a more balanced theory of graph machine learning, focusing on a more thorough understanding of the interplay of expressive power, generalization, and optimization."> Abstract</a>
                 <a href="https://arxiv.org/abs/2402.02287" class="btn btn-default">Paper </a>


             </div>
           </div><!-- end of row -->


           <!--Open problems -->
              <div class="row" id="templatemo_publications_LargeScaleBD">
                  <div class="col-md-1"></div>
                  <div class="col-md-5 col-sm-7 col-xs-24">
                      <img src="projects/spectral_expressive_power/rep.png" width="400" " alt="">
                  </div>
                  <div class="col-md-1"></div>
                  <div class="col-md-16">
                      <h2>On the Expressive Power of Spectral Invariant Graph Neural Networks</h2>
                      <p>
                        Bohang Zhang, Lingxiao Zhao, Haggai Maron <br>
                        <i>International Conference on Machine Learning (ICML) 2024</i> <br>

                      </p>
                      <a class="btn btn-default abstract" ptitle="Incorporating spectral information to enhance Graph Neural Networks (GNNs) has shown promising results but raises a fundamental challenge due to the inherent ambiguity of eigenvectors. Various architectures have been proposed to address this ambiguity, referred to as spectral invariant architectures. Notable examples include GNNs and Graph Transformers that use spectral distances, spectral projection matrices, or other invariant spectral features.
However, the potential expressive power of these spectral invariant architectures remains largely unclear. The goal of this work is to gain a deep theoretical understanding of the expressive power obtainable when using spectral features. We first introduce a novel message-passing framework for designing spectral invariant GNNs, called Eigenspace Projection GNN (EPNN). Our comprehensive analysis shows that EPNN essentially unifies all prior spectral invariant architectures, in that they are either strictly less expressive or equivalent to EPNN. A fine-grained expressiveness hierarchy among different architectures is also established. On the other hand, we present a surprising result that EPNN itself is bounded by a recently proposed class of Subgraph GNNs, implying that all these spectral invariant architectures are strictly less expressive than 3-WL. Finally, we demonstrate that these spectral features offer no additional advantage when combined with more expressive GNNs."> Abstract</a>
                      <a href="https://arxiv.org/abs/2406.04336" class="btn btn-default">Paper</a>


                  </div>
                </div><!-- end of row -->

      <!--Open problems -->
         <div class="row" id="templatemo_publications_LargeScaleBD">
             <div class="col-md-1"></div>
             <div class="col-md-5 col-sm-7 col-xs-24">
                 <img src="projects/network_align/rep.png" width="400" " alt="">
             </div>
             <div class="col-md-1"></div>
             <div class="col-md-16">
                 <h2>Equivariant Deep Weight Space Alignment</h2>
                 <p>
                   Aviv Navon, Aviv Shamsian, Ethan Fetaya, Gal Chechik, Nadav Dym, Haggai Maron <br>
                   <i>International Conference on Machine Learning (ICML) 2024</i> <br>

                 </p>
                 <a class="btn btn-default abstract" ptitle="Permutation symmetries of deep networks make simple operations like model averaging and similarity estimation challenging. In many cases, aligning the weights of the networks, i.e., finding optimal permutations between their weights, is necessary. More generally, weight alignment is essential for a wide range of applications, from model merging, through exploring the optimization landscape of deep neural networks, to defining meaningful distance functions between neural networks. Unfortunately, weight alignment is an NP-hard problem. Prior research has mainly focused on solving relaxed versions of the alignment problem, leading to either time-consuming methods or sub-optimal solutions. To accelerate the alignment process and improve its quality, we propose a novel framework aimed at learning to solve the weight alignment problem, which we name Deep-Align. To that end, we first demonstrate that weight alignment adheres to two fundamental symmetries and then, propose a deep architecture that respects these symmetries. Notably, our framework does not require any labeled data. We provide a theoretical analysis of our approach and evaluate Deep-Align on several types of network architectures and learning setups. Our experimental results indicate that a feed-forward pass with Deep-Align produces better or equivalent alignments compared to those produced by current optimization algorithms. Additionally, our alignments can be used as an initialization for other methods to gain even better solutions with a significant speedup in convergence."> Abstract</a>
                 <a href="https://arxiv.org/abs/2310.13397" class="btn btn-default">Paper </a>
                 <a href="https://github.com/AvivNavon/deep-align" class="btn btn-default">GitHub </a>




             </div>
           </div><!-- end of row -->

           <!--Open problems -->
              <div class="row" id="templatemo_publications_LargeScaleBD">
                  <div class="col-md-1"></div>
                  <div class="col-md-5 col-sm-7 col-xs-24">
                      <img src="projects/subgraphormer/rep.png" width="400" " alt="">
                  </div>
                  <div class="col-md-1"></div>
                  <div class="col-md-16">
                      <h2>Subgraphormer: Unifying Subgraph GNNs and Graph Transformers via Graph Products</h2>
                      <p>
                        Guy Bar-Shalom, Beatrice Bevilacqua, Haggai Maron <br>
                        <i>International Conference on Machine Learning (ICML) 2024</i> <br>
                        (A preliminary <a href="https://drive.google.com/file/d/1x1e4VjnW6Z3ubF_Q5YcjEBs4W471cTdo/view?usp=drive_link"> version </a> appeared in  <i> NeurIPS 2023 New Frontiers in Graph Learning Workshop </i> )<br>

                      </p>
                      <a class="btn btn-default abstract" ptitle="In the realm of Graph Neural Networks (GNNs), two exciting research directions have recently emerged: Subgraph GNNs and Graph Transformers. In this paper, we propose an architecture that integrates both approaches, dubbed Subgraphormer, which combines the enhanced expressive power, message-passing mechanisms, and aggregation schemes from Subgraph GNNs with attention and positional encodings, arguably the most important components in Graph Transformers. Our method is based on an intriguing new connection we reveal between Subgraph GNNs and product graphs, suggesting that Subgraph GNNs can be formulated as Message Passing Neural Networks (MPNNs) operating on a product of the graph with itself. We use this formulation to design our architecture: first, we devise an attention mechanism based on the connectivity of the product graph. Following this, we propose a novel and efficient positional encoding scheme for Subgraph GNNs, which we derive as a positional encoding for the product graph. Our experimental results demonstrate significant performance improvements over both Subgraph GNNs and Graph Transformers on a wide range of datasets."> Abstract</a>
                      <a href="https://arxiv.org/abs/2402.08450" class="btn btn-default">Paper </a>


                  </div>
                </div><!-- end of row -->

                <!--Open problems -->
                   <div class="row" id="templatemo_publications_LargeScaleBD">
                       <div class="col-md-1"></div>
                       <div class="col-md-5 col-sm-7 col-xs-24">
                           <img src="projects/weight_aug/rep.png" width="400" " alt="">
                       </div>
                       <div class="col-md-1"></div>
                       <div class="col-md-16">
                           <h2>Improved Generalization of Weight Space Networks via Augmentationss</h2>
                           <p> Aviv Shamsian, Aviv Navon, David W. Zhang, Yan Zhang, Ethan Fetaya, Gal Chechik, Haggai Maron <br>
                             <i>International Conference on Machine Learning (ICML) 2024</i> <br>
                              (A preliminary  <a href="projects/weight_aug/paper.pdf"> version </a> appeared in <i>Symmetry and Geometry in Neural Representations Workshop, 37th Annual Conference on Neural Information Processing Systems (NeurIPS 2023)  </i> as an <span style="color:red;">Oral Presentation</span>).

                           </p>
                           <a class="btn btn-default abstract" ptitle="Learning in deep weight spaces (DWS), where neural networks process the weights of other neural networks, is an emerging research direction, with applications to 2D and 3D neural fields (INRs, NeRFs), as well as making inferences about other types of neural networks. Unfortunately, weight space models tend to suffer from substantial overfitting. We empirically analyze the reasons for this overfitting and find that a key reason is the lack of diversity in DWS datasets. While a given object can be represented by many different weight configurations, typical INR training sets fail to capture variability across INRs that represent the same object. To address this, we explore strategies for data augmentation in weight spaces and propose a MixUp method adapted for weight spaces. We demonstrate the effectiveness of these methods in two setups. In classification, they improve performance similarly to having up to 10 times more data. In self-supervised contrastive learning, they yield substantial 5-10% gains in downstream classification."> Abstract</a>
                           <a href="https://arxiv.org/abs/2402.04081" class="btn btn-default">Paper </a>
                           <a href="https://github.com/AvivSham/deep-weight-space-augmentations" class="btn btn-default">GitHub </a>


                       </div>
                     </div><!-- end of row -->

      <!--Open problems -->
         <div class="row" id="templatemo_publications_LargeScaleBD">
             <div class="col-md-1"></div>
             <div class="col-md-5 col-sm-7 col-xs-24">
                 <img src="projects/choose_subgraphs/rep.png" width="400" " alt="">
             </div>
             <div class="col-md-1"></div>
             <div class="col-md-16">
                 <h2>Efficient Subgraph GNNs by Learning Effective Selection Policies</h2>
                 <p>
                   Beatrice Bevilacqua, Moshe Eliasof, Eli Meirom, Bruno Ribeiro, Haggai Maron <br>
                   <i>International Conference on Learning Representations (ICLR) 2024</i> <br>

                 </p>
                 <a class="btn btn-default abstract" ptitle="Subgraph GNNs are provably expressive neural architectures that learn graph representations from sets of subgraphs. Unfortunately, their applicability is hampered by the computational complexity associated with performing message passing on many subgraphs. In this paper, we consider the problem of learning to select a small subset of the large set of possible subgraphs in a data-driven fashion. We first motivate the problem by proving that there are families of WL-indistinguishable graphs for which there exist efficient subgraph selection policies: small subsets of subgraphs that can already identify all the graphs within the family. We then propose a new approach, called Policy-Learn, that learns how to select subgraphs in an iterative manner. We prove that, unlike popular random policies and prior work addressing the same problem, our architecture is able to learn the efficient policies mentioned above. Our experimental results demonstrate that Policy-Learn outperforms existing baselines across a wide range of datasets."> Abstract</a>
                 <a href="https://arxiv.org/abs/2310.20082" class="btn btn-default">Paper </a>


             </div>
           </div><!-- end of row -->





      <!--Open problems -->
         <div class="row" id="templatemo_publications_LargeScaleBD">
             <div class="col-md-1"></div>
             <div class="col-md-5 col-sm-7 col-xs-24">
                 <img src="projects/metanetworks/rep.png" width="400" " alt="">
             </div>
             <div class="col-md-1"></div>
             <div class="col-md-16">
                 <h2>Graph Metanetworks for Processing Diverse Neural Architectures</h2>
                 <p>
                   Derek Lim, Haggai Maron, Marc T. Law, Jonathan Lorraine, James Lucas <br>
                   <i>International Conference on Learning Representations (ICLR) 2024</i> <br>
                   <p style="color:red;">Spotlight Presentation</p>

                 </p>
                 <a class="btn btn-default abstract" ptitle="Neural networks efficiently encode learned information within their parameters. Consequently, many tasks can be unified by treating neural networks themselves as input data. When doing so, recent studies demonstrated the importance of accounting for the symmetries and geometry of parameter spaces. However, those works developed architectures tailored to specific networks such as MLPs and CNNs without normalization layers, and generalizing such architectures to other types of networks can be challenging. In this work, we overcome these challenges by building new metanetworks - neural networks that take weights from other neural networks as input. Put simply, we carefully build graphs representing the input neural networks and process the graphs using graph neural networks. Our approach, Graph Metanetworks (GMNs), generalizes to neural architectures where competing methods struggle, such as multi-head attention layers, normalization layers, convolutional layers, ResNet blocks, and group-equivariant linear layers. We prove that GMNs are expressive and equivariant to parameter permutation symmetries that leave the input neural network functions unchanged. We validate the effectiveness of our method on several metanetwork tasks over diverse neural network architectures."> Abstract</a>
                 <a href="https://arxiv.org/abs/2312.04501" class="btn btn-default">Paper </a>


             </div>
           </div><!-- end of row -->










      <!--Open problems -->
         <div class="row" id="templatemo_publications_LargeScaleBD">
             <div class="col-md-1"></div>
             <div class="col-md-5 col-sm-7 col-xs-24">
                 <img src="projects/signequi/rep.png" width="300" " alt="">
             </div>
             <div class="col-md-1"></div>
             <div class="col-md-16">
                 <h2>Expressive Sign Equivariant Networks for Spectral Geometric Learning</h2>
                 <p>
                   Derek Lim, Joshua Robinson, Stefanie Jegelka, Haggai Maron<br>
                   <i>37th Annual Conference on Neural Information Processing Systems (NeurIPS 2023)  </i> <br>
                   <p style="color:red;">Spotlight Presentation</p>

                 </p>
                 <a class="btn btn-default abstract" ptitle="Recent work has shown the utility of developing machine learning models that respect the symmetries of eigenvectors.
              These works promote sign invariance, since for any eigenvector $v$ the negation $-v$ is also an eigenvector.
In this work, we demonstrate that sign \emph{equivariance} is useful for applications such as building orthogonally equivariant models and link prediction.
To obtain these benefits, we develop novel sign equivariant neural network architectures. These models are based on our analytic characterization of the sign equivariant polynomials  and thus inherit provable expressiveness properties."> Abstract</a>
                 <a href="" class="btn btn-default">Paper </a>


             </div>
           </div><!-- end of row -->


      <!--Open problems -->
         <div class="row" id="templatemo_publications_LargeScaleBD">
             <div class="col-md-1"></div>
             <div class="col-md-5 col-sm-7 col-xs-24">
                 <img src="projects/norm-guided/rep.png" width="300" " alt="">
             </div>
             <div class="col-md-1"></div>
             <div class="col-md-16">
                 <h2>Norm-guided latent space exploration for text-to-image generation</h2>
                 <p>
                   Dvir Samuel, Rami Ben-Ari, Nir Darshan, Haggai Maron, Gal Chechik <br>
                   <i>37th Annual Conference on Neural Information Processing Systems (NeurIPS 2023)  </i> <br>
                   </p>
                 </p>
                 <a class="btn btn-default abstract" ptitle="Text-to-image diffusion models show great potential in synthesizing a large variety of concepts in new compositions and scenarios. However, their latent seed space is still not well understood and has been shown to have an impact in generating new and rare concepts. Specifically, simple operations like interpolation and centroid finding work poorly with the standard Euclidean and spherical metrics in the latent space. This paper makes the observation that current training procedures make diffusion models biased toward inputs with a narrow range of norm values. This has strong implications for methods that rely on seed manipulation for image generation that can be further applied to few-shot and long-tail learning tasks. To address this issue, we propose a novel method for interpolating between two seeds and demonstrate that it defines a new non-Euclidean metric that takes into account a norm-based prior on seeds. We describe a simple yet efficient algorithm for approximating this metric and use it to further define centroids in the latent seed space. We show that our new interpolation and centroid evaluation techniques significantly enhance the generation of rare concept images. This further leads to state-of-the-art performance on few-shot and long-tail benchmarks, improving prior approach in terms of generation speed, image quality, and semantic content."> Abstract</a>
                 <a href="https://arxiv.org/abs/2306.08687" class="btn btn-default">Paper </a>
                 <a href="https://github.com/dvirsamuel/SeedSelect" class="btn btn-default">Code </a>
             </div>
           </div><!-- end of row -->



      <!--Open problems -->
         <div class="row" id="templatemo_publications_LargeScaleBD">
             <div class="col-md-1"></div>
             <div class="col-md-5 col-sm-7 col-xs-24">
                 <img src="projects/DWS/rep.png" width="300" " alt="">
             </div>
             <div class="col-md-1"></div>
             <div class="col-md-16">
                 <h2>Equivariant Architectures for Learning in Deep Weight Spaces</h2>
                 <p>
                   Aviv Navon, Aviv Shamsian, Idan Achituve, Ethan Fetaya, Gal Chechik, Haggai Maron<br>
                   <i>International Conference on Machine Learning (ICML) 2023</i> <br>
                   </p>
                   <p style="color:red;">Oral Presentation</p>
                 </p>
                 <a class="btn btn-default abstract" ptitle="Designing machine learning architectures for processing neural networks in their raw weight matrix form is a newly introduced research direction. Unfortunately, the unique symmetry structure of deep weight spaces makes this design very challenging. If successful, such architectures would be capable of performing a wide range of intriguing tasks, from adapting a pre-trained network to a new domain to editing objects represented as functions (INRs or NeRFs). As a first step towards this goal, we present here a novel network architecture for learning in deep weight spaces. It takes as input a concatenation of weights and biases of a pre-trained MLP and processes it using a composition of layers that are equivariant to the natural permutation symmetry of the MLP's weights: Changing the order of neurons in intermediate layers of the MLP does not affect the function it represents. We provide a full characterization of all affine equivariant and invariant layers for these symmetries and show how these layers can be implemented using three basic operations: pooling, broadcasting, and fully connected layers applied to the input in an appropriate manner. We demonstrate the effectiveness of our architecture and its advantages over natural baselines in a variety of learning tasks."> Abstract</a>
                 <a href="https://arxiv.org/abs/2301.12780" class="btn btn-default">Paper </a>
                 <a href="https://www.youtube.com/watch?v=B9xFem6_ckQ&t=8182s" class="btn btn-default">Talk </a>
                 <a href="https://avivnavon.github.io/DWSNets/" class="btn btn-default">Code </a>
                 <a href="                 https://developer.nvidia.com/blog/designing-deep-networks-to-process-other-deep-networks/" class="btn btn-default">Blog </a>

             </div>
           </div><!-- end of row -->

      <!--Open problems -->
         <div class="row" id="templatemo_publications_LargeScaleBD">
             <div class="col-md-1"></div>
             <div class="col-md-5 col-sm-7 col-xs-24">
                 <img src="projects/RFP/rep.png" width="300" " alt="">
             </div>
             <div class="col-md-1"></div>
             <div class="col-md-16">
                 <h2>Graph Positional Encoding via Random Feature Propagation</h2>
                 <p>
                   Moshe Eliasof, Fabrizio Frasca, Beatrice Bevilacqua, Eran Treister, Gal Chechik, Haggai Maron<br>
                   <i>International Conference on Machine Learning (ICML) 2023</i> <br>
                   </p>
                 </p>
                 <a class="btn btn-default abstract" ptitle="Two main families of node feature augmentation schemes have been explored for enhancing GNNs: random features and spectral positional encoding. Surprisingly, however, there is still no clear understanding of the relation between these two augmentation schemes. Here we propose a novel family of positional encoding schemes which draws a link between the above two approaches and improves over both. The new approach, named Random Feature Propagation (RFP), is inspired by the power iteration method and its generalizations. It concatenates several intermediate steps of an iterative algorithm for computing the dominant eigenvectors of a propagation matrix, starting from random node features. Notably, these propagation steps are based on graph-dependent propagation operators that can be either predefined or learned. We explore the theoretical and empirical benefits of RFP. First, we provide theoretical justifications for using random features, for incorporating early propagation steps, and for using multiple random initializations. Then, we empirically demonstrate that RFP significantly outperforms both spectral PE and random features in multiple node classification and graph classification benchmarks."> Abstract</a>
                 <a href="https://arxiv.org/abs/2303.02918" class="btn btn-default">Paper </a>
             </div>
           </div><!-- end of row -->

      <!--Open problems -->
         <div class="row" id="templatemo_publications_LargeScaleBD">
             <div class="col-md-1"></div>
             <div class="col-md-5 col-sm-7 col-xs-24">
                 <img src="projects/equipoly/rep.png" width="300" " alt="">
             </div>
             <div class="col-md-1"></div>
             <div class="col-md-16">
                 <h2>Equivariant Polynomials for Graph Neural Networks</h2>
                 <p>
                   Omri Puny, Derek Lim, Bobak T. Kiani, Haggai Maron, Yaron Lipman<br>
                   <i>International Conference on Machine Learning (ICML) 2023</i> <br>
                   </p>
                   <p style="color:red;">Oral Presentation</p>
                 </p>
                 <a class="btn btn-default abstract" ptitle="Graph Neural Networks (GNN) are inherently limited in their expressive power. Recent seminal works (Xu et al., 2019; Morris et al., 2019b) introduced the Weisfeiler-Lehman (WL) hierarchy as a measure of expressive power. Although this hierarchy has propelled significant advances in GNN analysis and architecture developments, it suffers from several significant limitations. These include a complex definition that lacks direct guidance for model improvement and a WL hierarchy that is too coarse to study current GNNs. This paper introduces an alternative expressive power hierarchy based on the ability of GNNs to calculate equivariant polynomials of a certain degree. As a first step, we provide a full characterization of all equivariant graph polynomials by introducing a concrete basis, significantly generalizing previous results. Each basis element corresponds to a specific multi-graph, and its computation over some graph data input corresponds to a tensor contraction problem. Second, we propose algorithmic tools for evaluating the expressiveness of GNNs using tensor contraction sequences, and calculate the expressive power of popular GNNs. Finally, we enhance the expressivity of common GNN architectures by adding polynomial features or additional operations / aggregations inspired by our theory. These enhanced GNNs demonstrate state-of-the-art results in experiments across multiple graph learning benchmarks."> Abstract</a>
                 <a href="https://arxiv.org/abs/2302.11556" class="btn btn-default">Paper </a>
                 <a href="https://github.com/omri1348/Equivariant-Polynomaials" class="btn btn-default">Code </a>

             </div>
           </div><!-- end of row -->








      <!--Open problems -->
         <div class="row" id="templatemo_publications_LargeScaleBD">
             <div class="col-md-1"></div>
             <div class="col-md-5 col-sm-7 col-xs-24">
                 <img src="projects/signnet/rep.png" width="300" " alt="">
             </div>
             <div class="col-md-1"></div>
             <div class="col-md-16">
                 <h2>Sign and Basis Invariant Networks for Spectral Graph Representation Learning</h2>
                 <p>
                   Derek Lim*, Joshua Robinson*, Lingxiao Zhao, Tess Smidt, Suvrit Sra, Haggai Maron, Stefanie Jegelka<br>
                   <i> International Conference on Learning Representations (ICLR 2023)  </i> <br>
                   <p style="color:red;"> notable-top-25% paper (AKA Spotlight) </p> <br>

                 </p>
                 <a class="btn btn-default abstract" ptitle="Many machine learning tasks involve processing eigenvectors derived from data. Especially valuable are Laplacian eigenvectors, which capture useful structural information about graphs and other geometric objects. However, ambiguities arise when computing eigenvectors: for each eigenvector v, the sign flipped −v is also an eigenvector. More generally, higher dimensional eigenspaces contain infinitely many choices of basis eigenvectors. These ambiguities make it a challenge to process eigenvectors and eigenspaces in a consistent way. In this work we introduce SignNet and BasisNet -- new neural architectures that are invariant to all requisite symmetries and hence process collections of eigenspaces in a principled manner. Our networks are universal, i.e., they can approximate any continuous function of eigenvectors with the proper invariances. They are also theoretically strong for graph representation learning -- they can approximate any spectral graph convolution, can compute spectral invariants that go beyond message passing neural networks, and can provably simulate previously proposed graph positional encodings. Experiments show the strength of our networks for learning spectral graph filters and learning graph positional encodings."> Abstract</a>
                 <a href="https://arxiv.org/abs/2202.13013" class="btn btn-default">Paper </a>
                 <a href="https://github.com/cptq/SignNet-BasisNet" class="btn btn-default">Code </a>


             </div>
           </div><!-- end of row -->




      <!--Open problems -->
         <div class="row" id="templatemo_publications_LargeScaleBD">
             <div class="col-md-1"></div>
             <div class="col-md-5 col-sm-7 col-xs-24">
                 <img src="projects/rethinking_subgraphs/rep.png" width="300" " alt="">
             </div>
             <div class="col-md-1"></div>
             <div class="col-md-16">
                 <h2>Understanding and Extending Subgraph GNNs by Rethinking Their Symmetries</h2>
                 <p>
                   Fabrizio Frasca*, Beatrice Bevilacqua*, Michael M. Bronstein, Haggai Maron

                   <br>
                   <i> 36th Annual Conference on Neural Information Processing Systems (NeurIPS 2022)  </i>
                   <p style="color:red;"> Oral presentation (1.7% acceptance rate)</p> <br>
                 </p>
                 <a class="btn btn-default abstract" ptitle="Subgraph GNNs are a recent class of expressive Graph Neural Networks (GNNs) which model graphs as collections of subgraphs. So far, the design space of possible Subgraph GNN architectures as well as their basic theoretical properties are still largely unexplored. In this paper, we study the most prominent form of subgraph methods, which employs node-based subgraph selection policies such as ego-networks or node marking and deletion. We address two central questions: (1) \emph{What is the upper-bound of the expressive power of these methods?} and (2) \emph{What is the family of equivariant message passing layers on these sets of subgraphs?}.
Our first step in answering these questions is a novel symmetry analysis which shows that modelling the symmetries of node-based subgraph collections requires a significantly smaller symmetry group than the one adopted in previous works. This analysis is then used to establish a link between Subgraph GNNs and Invariant Graph Networks (IGNs).
We answer the questions above by first bounding the expressive power of subgraph methods by 3-WL, and then proposing a general family of message-passing layers for subgraph methods that generalises all previous node-based Subgraph GNNs. Finally, we design a novel Subgraph GNN dubbed \SUN{}, which theoretically unifies previous architectures while providing better empirical performance on multiple benchmarks."> Abstract</a>
                 <a href="https://arxiv.org/abs/2206.11140" class="btn btn-default">Paper </a>
                 <a href="https://github.com/beabevi/SUN" class="btn btn-default">Code </a>
                 <a href="https://library.cirm-math.fr/Record.htm?idlist=1&record=19280739124910089119" class="btn btn-default"> Talk</a>


             </div>
           </div><!-- end of row -->




           <!--Open problems -->
              <div class="row" id="templatemo_publications_LargeScaleBD">
                  <div class="col-md-1"></div>
                  <div class="col-md-5 col-sm-7 col-xs-24">
                      <img src="projects/gen_pos_enc/rep.png" width="300" " alt="">
                  </div>
                  <div class="col-md-1"></div>
                  <div class="col-md-16">
                      <h2>	Generalized Laplacian Positional Encoding for Graph Representation Learning</h2>
                      <p>
                      Sohir Maskey*, Ali Parviz*, Maximilian Thiessen, Hannes Stärk, Ylli Sadikaj, Haggai Maron<br>
                        <i> NeurIPS 2022 Workshop on Symmetry and Geometry in Neural Representations  </i> <br>
                      </p>
                      <a class="btn btn-default abstract" ptitle="Graph neural networks (GNNs) are the primary tool for processing graph-structured data. Unfortunately, the most commonly used GNNs, called Message Passing Neural Networks (MPNNs) suffer from several fundamental limitations. To overcome these limitations, recent works have adapted the idea of positional encodings to graph data. This paper draws inspiration from the recent success of Laplacian-based positional encoding and defines a novel family of positional encoding schemes for graphs. We accomplish this by generalizing the optimization problem that defines the Laplace embedding to more general dissimilarity functions rather than the 2-norm used in the original formulation. This family of positional encodings is then instantiated by considering p-norms. We discuss a method for calculating these  positional encoding schemes, implement it in PyTorch and demonstrate how the resulting positional encoding captures different properties of the graph. Furthermore, we demonstrate that this novel family of positional encodings can improve the expressive power of MPNNs. Lastly, we present preliminary experimental results."> Abstract</a>
                      <a href="https://arxiv.org/abs/2210.15956" class="btn btn-default">Paper </a>
                  </div>
                </div><!-- end of row -->





           <!--Open problems -->
              <div class="row" id="templatemo_publications_LargeScaleBD">
                  <div class="col-md-1"></div>
                  <div class="col-md-5 col-sm-7 col-xs-24">
                      <img src="projects/simple_rot_equi/rep.png" width="300" " alt="">
                  </div>
                  <div class="col-md-1"></div>
                  <div class="col-md-16">
                      <h2>A Simple and Universal Rotation Equivariant Point-cloud Network </h2>
                      <p>
                        Ben Finkelshtein, Chaim Baskin, Haggai Maron, Nadav Dym<br>
                        <i> Workshop on Topology, Algebra, and Geometry in Learning, ICML 2022  </i> <br>
                      </p>
                      <a class="btn btn-default abstract" ptitle="Equivariance to permutations and rigid motions is an important inductive bias for various 3D learning problems. Recently it has been shown that the equivariant Tensor Field Network architecture is universal -- it can approximate any equivariant function. In this paper we suggest a much simpler architecture, prove that it enjoys the same universality guarantees and evaluate its performance on Modelnet40. "> Abstract</a>
                      <a href="https://arxiv.org/abs/2203.01216" class="btn btn-default">Paper </a>
                      <a href="https://github.com/simpleinvariance/UniversalNetwork" class="btn btn-default">Code </a>


                  </div>
                </div><!-- end of row -->

           <!--Open problems -->
              <div class="row" id="templatemo_publications_LargeScaleBD">
                  <div class="col-md-1"></div>
                  <div class="col-md-5 col-sm-7 col-xs-24">
                      <img src="projects/mtl/rep.png" width="300" " alt="">
                  </div>
                  <div class="col-md-1"></div>
                  <div class="col-md-16">
                      <h2>Multi-Task Learning as a Bargaining Game</h2>
                      <p>
                        Aviv Navon, Aviv Shamsian, Idan Achituve, Haggai Maron, Kenji Kawaguchi,Gal Chechik,Ethan Fetaya <br>
                        <i> International Conference on Machine Learning (ICML) 2022  </i> <br>
                      </p>
                      <a class="btn btn-default abstract" ptitle="In Multi-task learning (MTL), a joint model is trained to simultaneously make predictions for several tasks. Joint training reduces computation costs and improves data efficiency; however, since the gradients of these different tasks may conflict, training a joint model for MTL often yields lower performance than its corresponding single-task counterparts. A common method for alleviating this issue is to combine per-task gradients into a joint update direction using a particular heuristic. In this paper, we propose viewing the gradients combination step as a bargaining game, where tasks negotiate to reach an agreement on a joint direction of parameter update. Under certain assumptions, the bargaining problem has a unique solution, known as the \emph{Nash Bargaining Solution}, which we propose to use as a principled approach to multi-task learning. We describe a new MTL optimization procedure, Nash-MTL, and derive theoretical guarantees for its convergence. Empirically, we show that Nash-MTL achieves state-of-the-art results on multiple MTL benchmarks in various domains."> Abstract</a>
                      <a href="https://arxiv.org/abs/2202.01017" class="btn btn-default">Paper </a>
                  </div>
                </div><!-- end of row -->


                <!--Open problems -->
                   <div class="row" id="templatemo_publications_LargeScaleBD">
                       <div class="col-md-1"></div>
                       <div class="col-md-5 col-sm-7 col-xs-24">
                           <img src="projects/tensor_contraction/rep.png" width="300" " alt="">
                       </div>
                       <div class="col-md-1"></div>
                       <div class="col-md-16">
                           <h2>Optimizing Tensor Network Contraction Using Reinforcement Learning</h2>
                           <p>
                             Eli A Meirom, Haggai Maron, Shie Mannor, Gal Chechik <br>
                             <i> International Conference on Machine Learning (ICML) 2022 </i> <br>
                             Also in <i> The Multi-disciplinary Conference on Reinforcement Learning and Decision Making, RLDM 2022 </i> <br>
                           </p>
                           <a class="btn btn-default abstract" ptitle="Quantum Computing (QC) stands to revolutionize computing, but is currently still limited. To develop and test quantum algorithms today, quantum circuits are often simulated on classical computers. Simulating a complex quantum circuit requires computing the contraction of a large network of tensors. The order (path) of contraction can have a drastic effect on the computing cost, but finding an efficient order is a challenging combinatorial optimization problem. We propose a Reinforcement Learning (RL) approach combined with Graph Neural Networks (GNN) to address the contraction ordering problem. The problem is extremely challenging due to the huge search space, the heavy-tailed reward distribution, and the challenging credit assignment. We show how a carefully implemented RL-agent that uses a GNN as the basic policy construct can address these challenges and obtain significant improvements over state-of-the-art techniques in three varieties of circuits, including the largest scale networks used in contemporary QC."> Abstract</a>
                           <a href="https://arxiv.org/abs/2204.09052" class="btn btn-default">Paper </a>
                       </div>
                     </div><!-- end of row -->


      <!--Open problems -->
         <div class="row" id="templatemo_publications_LargeScaleBD">
             <div class="col-md-1"></div>
             <div class="col-md-5 col-sm-7 col-xs-24">
                 <img src="projects/federated_graph_hn/rep.png" width="300" " alt="">
             </div>
             <div class="col-md-1"></div>
             <div class="col-md-16">
                 <h2>Federated Learning with Heterogeneous Architectures using Graph HyperNetworks</h2>
                 <p>
                   Or Litany, Haggai Maron, David Acuna, Jan Kautz, Gal Chechik, Sanja Fidler<br>
                   <i> Technical report, January 2022  </i> <br>
                 </p>
                 <a class="btn btn-default abstract" ptitle="Standard Federated Learning (FL) techniques are limited to clients with identical network architectures. This restricts potential use-cases like cross-platform training or inter-organizational collaboration when both data privacy and architectural proprietary are required. We propose a new FL framework that accommodates heterogeneous client architecture by adopting a graph hypernetwork for parameter sharing. A property of the graph hyper network is that it can adapt to various computational graphs, thereby allowing meaningful parameter sharing across models. Unlike existing solutions, our framework does not limit the clients to share the same architecture type, makes no use of external data and does not require clients to disclose their model architecture. Compared with distillation-based and non-graph hypernetwork baselines, our method performs notably better on standard benchmarks. We additionally show encouraging generalization performance to unseen architectures."> Abstract</a>
                 <a href="https://arxiv.org/abs/2201.08459" class="btn btn-default">Paper </a>
             </div>
           </div><!-- end of row -->





      <!--Open problems -->
         <div class="row" id="templatemo_publications_LargeScaleBD">
             <div class="col-md-1"></div>
             <div class="col-md-5 col-sm-7 col-xs-24">
                 <img src="projects/ESAN/rep.png" width="300" " alt="">
             </div>
             <div class="col-md-1"></div>
             <div class="col-md-16">
                 <h2>Equivariant Subgraph Aggregation Networks</h2>
                 <p>
                   Beatrice Bevilacqua*, Fabrizio Frasca*, Derek Lim*, Balasubramaniam Srinivasan, Chen Cai, Gopinath Balamurugan, Michael M. Bronstein, Haggai Maron (*equal contribution)<br>
                   <i> International Conference on Learning Representations (ICLR) 2022   </i> <br>
                   <p style="color:red;"> Spotlight presentation (5% acceptance rate)</p>

                 </p>
                 <a class="btn btn-default abstract" ptitle="Message-passing neural networks (MPNNs) are the leading architecture for deep learning on graph-structured data, in large part due to their simplicity and scalability. Unfortunately, it was shown that these architectures are limited in their expressive power. This paper proposes a novel framework called Equivariant Subgraph Aggregation Networks (ESAN) to address this issue. Our main observation is that while two graphs may not be distinguishable by an MPNN, they often contain distinguishable subgraphs. Thus, we propose to represent each graph as a set of subgraphs derived by some predefined policy, and to process it using a suitable equivariant architecture. We develop novel variants of the 1-dimensional Weisfeiler-Leman (1-WL) test for graph isomorphism, and prove lower bounds on the expressiveness of ESAN in terms of these new WL variants. We further prove that our approach increases the expressive power of both MPNNs and more expressive architectures. Moreover, we provide theoretical results that describe how design choices such as the subgraph selection policy and equivariant neural architecture affect our architecture's expressive power. To deal with the increased computational cost, we propose a subgraph sampling scheme, which can be viewed as a stochastic version of our framework. A comprehensive set of experiments on real and synthetic datasets demonstrates that our framework improves the expressive power and overall performance of popular GNN architectures."> Abstract</a>
                 <a href="https://arxiv.org/abs/2110.02910" class="btn btn-default">Paper </a>
                 <a href="https://github.com/beabevi/ESAN" class="btn btn-default">GitHub</a>
                 <a href="https://towardsdatascience.com/using-subgraphs-for-more-expressive-gnns-8d06418d5ab" class="btn btn-default">Blog post </a>
                 <a href="https://library.cirm-math.fr/Record.htm?idlist=1&record=19280739124910089119" class="btn btn-default"> Talk</a>


             </div>
           </div><!-- end of row -->
           <!--Open problems -->
              <div class="row" id="templatemo_publications_LargeScaleBD">
                  <div class="col-md-1"></div>
                  <div class="col-md-5 col-sm-7 col-xs-24">
                      <img src="projects/wl_survey/rep.png" width="300" " alt="">
                  </div>
                  <div class="col-md-1"></div>
                  <div class="col-md-16">
                      <h2>Weisfeiler and Leman go Machine Learning: The Story so far</h2>
                      <p>
                        Christopher Morris, Yaron Lipman, Haggai Maron, Bastian Rieck, Nils M. Kriege, Martin Grohe, Matthias Fey, Karsten Borgwardt<br>
                        <i> Technical report, December 2021  </i> <br>
                      </p>
                      <a class="btn btn-default abstract" ptitle="In recent years, algorithms and neural architectures based on the Weisfeiler-Leman algorithm, a well-known heuristic for the graph isomorphism problem, emerged as a powerful tool for machine learning with graphs and relational data. Here, we give a comprehensive overview of the algorithm's use in a machine learning setting, focusing on the supervised regime. We discuss the theoretical background, show how to use it for supervised graph- and node representation learning, discuss recent extensions, and outline the algorithm's connection to (permutation-)equivariant neural architectures. Moreover, we give an overview of current applications and future directions to stimulate further research."> Abstract</a>
                      <a href="https://arxiv.org/abs/2112.09992" class="btn btn-default">Paper </a>
                  </div>

           </div><!-- end of row -->


      <!--Open problems -->
         <div class="row" id="templatemo_publications_LargeScaleBD">
             <div class="col-md-1"></div>
             <div class="col-md-5 col-sm-7 col-xs-24">
                 <img src="projects/NADA/rep.png" width="300" " alt="">
             </div>
             <div class="col-md-1"></div>
             <div class="col-md-16">
                 <h2>StyleGAN-NADA: CLIP-Guided Domain Adaptation of Image Generators</h2>
                 <p>
                   Rinon Gal, Or Patashnik , Haggai Maron , Gal Chechik , Daniel Cohen-Or<br>
                   <i> ACM SIGGRAPH 2022  </i> <br>
                 </p>
                 <a class="btn btn-default abstract" ptitle="Can a generative model be trained to produce images from a specific domain, guided by a text prompt only, without seeing any image? In other words: can an image generator be trained blindly? Leveraging the semantic power of large scale Contrastive-Language-Image-Pre-training (CLIP) models, we present a text-driven method that allows shifting a generative model to new domains, without having to collect even a single image from those domains. We show that through natural language prompts and a few minutes of training, our method can adapt a generator across a multitude of domains characterized by diverse styles and shapes. Notably, many of these modifications would be difficult or outright impossible to reach with existing methods. We conduct an extensive set of experiments and comparisons across a wide range of domains. These demonstrate the effectiveness of our approach and show that our shifted models maintain the latent-space properties that make generative models appealing for downstream tasks."> Abstract</a>
                 <a href="https://arxiv.org/abs/2108.00946" class="btn btn-default">Paper </a>
                 <a href="https://github.com/rinongal/StyleGAN-nada" class="btn btn-default">Code </a>
                 <a href="https://replicate.com/rinongal/stylegan-nada" class="btn btn-default">Interactive demo </a>




             </div>

      </div><!-- end of row -->




      <!--Open problems -->
         <div class="row" id="templatemo_publications_LargeScaleBD">
             <div class="col-md-1"></div>
             <div class="col-md-5 col-sm-7 col-xs-24">
                 <img src="projects/equi_sfm/rep.png" width="300" " alt="">
             </div>
             <div class="col-md-1"></div>
             <div class="col-md-16">
                 <h2>Deep Permutation Equivariant Structure from Motion</h2>
                 <p>
                   Dror Moran, Hodaya Koslowsky, Yoni Kasten, Haggai Maron, Meirav Galun, Ronen Basri<br>
                   <i> International Conference on Computer Vision (ICCV) 2021  </i> <br>
                   <p style="color:red;"> Oral presentation (3% acceptance rate)</p>
                 </p>
                 <a class="btn btn-default abstract" ptitle="Existing deep methods produce highly accurate 3D reconstructions in stereo and multiview stereo settings, i.e., when cameras are both internally and externally calibrated. Nevertheless, the challenge of simultaneous recovery of camera poses and 3D scene structure in multiview settings with deep networks is still outstanding. Inspired by projective factorization for Structure from Motion (SFM) and by deep matrix completion techniques, we propose a neural network architecture that, given a set of point tracks in multiple images of a static scene, recovers both the camera parameters and a (sparse) scene structure by minimizing an unsupervised reprojection loss. Our network architecture is designed to respect the structure of the problem: the sought output is equivariant to permutations of both cameras and scene points. Notably, our method does not require initialization of camera parameters or 3D point locations. We test our architecture in two setups: (1) single scene reconstruction and (2) learning from multiple scenes. Our experiments, conducted on a variety of datasets in both internally calibrated and uncalibrated settings, indicate that our method accurately recovers pose and structure, on par with classical state of the art methods. Additionally, we show that a pre-trained network can be used to reconstruct novel scenes using inexpensive fine-tuning with no loss of accuracy."> Abstract</a>
                 <a href="https://arxiv.org/pdf/2104.06703.pdf" class="btn btn-default">Paper </a>
                 <a href="https://github.com/drormoran/Equivariant-SFM" class="btn btn-default">Code </a>

             </div>

      </div><!-- end of row -->

      <!--Open problems -->
         <div class="row" id="templatemo_publications_LargeScaleBD">
             <div class="col-md-1"></div>
             <div class="col-md-5 col-sm-7 col-xs-24">
                 <img src="projects/jets/rep.png" width="450" " alt="">
             </div>
             <div class="col-md-1"></div>
             <div class="col-md-16">
                 <h2>Secondary Vertex Finding in Jets with Neural Networks</h2>
                 <p>
                 Jonathan Shlomi, Sanmay Ganguly, Eilam Gross, Kyle Cranmer, Yaron Lipman, Hadar Serviansky, Haggai Maron, Nimrod Segol<br>
                 <i>European Physical Journal C, 2021</i> <br>
                 </p>
                 <a class="btn btn-default abstract" ptitle="Jet classification is an important ingredient in measurements and searches for new physics at particle coliders, and secondary vertex reconstruction is a key intermediate step in building powerful jet classifiers. We use a neural network to perform vertex finding inside jets in order to improve the classification performance, with a focus on separation of bottom vs. charm flavor tagging. We implement a novel, universal set-to-graph model, which takes into account information from all tracks in a jet to determine if pairs of tracks originated from a common vertex. We explore different performance metrics and find our method to outperform traditional approaches in accurate secondary vertex reconstruction."> Abstract</a>
                 <a href="https://arxiv.org/abs/2008.02831" class="btn btn-default">Paper </a>


             </div>
      </div><!-- end of row -->

      <!--Open problems -->
         <div class="row" id="templatemo_publications_LargeScaleBD">
             <div class="col-md-1"></div>
             <div class="col-md-5 col-sm-7 col-xs-24">
                 <img src="projects/dereverb/rep.png" width="300" " alt="">
             </div>
             <div class="col-md-1"></div>
             <div class="col-md-16">
                 <h2>Scene-Agnostic Multi-Microphone Speech Dereverberation</h2>
                 <p>
                   Yochai Yemini, Ethan Fetaya, Haggai Maron, Sharon Gannot<br>
                   <i> INTERSPEECH 2021 </i> <br>
                 </p>
                 <a class="btn btn-default abstract" ptitle="Neural networks (NNs) have been widely applied in speech processing tasks, and, in particular, those employing microphone arrays. Nevertheless, most of the existing NN architectures can only deal with fixed and position-specific microphones arrays. In this paper, we present an NN architecture that is able to cope with microphone arrays on which no prior knowledge is presumed, and demonstrate its applicability on the speech dereverberation problem. To this end, our approach harnesses recent advances in the Deep Sets framework \cite{zaheer,sets} to design an architecture that enhances the reveberant log-spectrum. We provide a setup for training and testing such a network. Our experiments, using REVERB challenge datasets,  show that the proposed position-agnostic setup performs comparably with the position-aware framework and sometimes slightly better, even with less microphones. In addition, it substantially improves performance over the closest single microphone architecture. "> Abstract</a>
                 <a href="https://arxiv.org/pdf/2010.11875.pdf" class="btn btn-default">Paper </a>
                 <a href="https://github.com/yochaiye/scene_agnostic_dereverberation" class="btn btn-default">Code </a>

             </div>

      </div><!-- end of row -->

    </div>
    <!--Open problems -->
       <div class="row" id="templatemo_publications_LargeScaleBD">
           <div class="col-md-1"></div>
           <div class="col-md-5 col-sm-7 col-xs-24">
               <img src="projects/size_gen/rep.png" width="450" " alt="">
           </div>
           <div class="col-md-1"></div>
           <div class="col-md-16">
               <h2>From Local Structures to Size Generalization in Graph Neural Networks</h2>
               <p>
                 Gilad Yehudai, Ethan Fetaya, Eli Meirom, Gal Chechik, Haggai Maron<br>
                   <i>International Conference on Machine Learning (ICML) 2021</i> <br>
               </p>
               <a class="btn btn-default abstract" ptitle="Graph neural networks (GNNs) can process graphs of different sizes but their capacity to generalize across sizes is still not well understood. Size generalization is key to numerous GNN applications, from solving combinatorial optimization problems to learning in molecular biology. In such problems, obtaining labels and training on large graphs can be prohibitively expensive, but training on smaller graphs is possible.
This paper puts forward the size-generalization question and characterizes important aspects of that problem theoretically and empirically. We show that even for very simple tasks, GNNs do not naturally generalize to graphs of larger size. Instead, their generalization performance is closely related to the distribution of patterns of connectivity and features and how that distribution changes from small to large graphs. Specifically, we show that in many cases, there are GNNs that can perfectly solve a task on small graphs but generalize poorly to large graphs and that these GNNs are encountered in practice. We then formalize size generalization as a domain-adaption problem and describe two learning setups where size generalization can be improved. First, as a self-supervised learning problem (SSL) over the target domain of large graphs. Second, as a semi-supervised learning problem when few samples are available in the target domain. We demonstrate the efficacy of these solutions on a diverse set of benchmark graph datasets."> Abstract</a>
               <a href="https://arxiv.org/pdf/2010.08853" class="btn btn-default">Paper </a>
           </div>
    </div><!-- end of row -->



</div>
<!--Open problems -->
   <div class="row" id="templatemo_publications_LargeScaleBD">
       <div class="col-md-1"></div>
       <div class="col-md-5 col-sm-7 col-xs-24">
           <img src="projects/epidemic/rep.png" width="450" " alt="">
       </div>
       <div class="col-md-1"></div>
       <div class="col-md-16">
           <h2>Controlling Graph Dynamics with Reinforcement Learning and Graph Neural Networks</h2>
           <p>
            Eli A Meirom, Haggai Maron, Shie Mannor, Gal Chechik<br>
               <i>International Conference on Machine Learning (ICML) 2021</i> <br>
           </p>
           <a class="btn btn-default abstract" ptitle="We consider the problem of monitoring and controlling a partially-observed dynamic process that spreads over a graph. This problem naturally arises in contexts such as scheduling virus tests or quarantining individuals to curb a spreading epidemic; detecting fake news spreading on online networks by manually inspecting posted articles; and targeted marketing where the objective is to encourage the spread of a product. Curbing the spread and constraining the fraction of infected population becomes challenging when only a fraction of the population can be tested or quarantined.
To address this challenge, we formulate this setup as a sequential decision problem over a graph. In face of an exponential state space, combinatorial action space and partial observability, we design RLGN, a novel tractable Reinforcement Learning (RL) scheme to prioritize which nodes should be tested, using Graph Neural Networks (GNNs) to rank the graph nodes. We evaluate this approach in three types of social-networks: community-structured, preferential attachment, and based on statistics from real cellular tracking. RLGN consistently outperforms all baselines in our experiments. It suggests that prioritizing tests using RL on temporal graphs can increase the number of healthy people by 25% and contain the epidemic 30% more often than supervised approaches and 2.5X more often than non-learned baselines using the same resources."> Abstract</a>
           <a href="https://arxiv.org/pdf/2010.05313" class="btn btn-default">Paper </a>
       </div>
</div><!-- end of row -->

</div>
<!--Open problems -->
   <div class="row" id="templatemo_publications_LargeScaleBD">
       <div class="col-md-1"></div>
       <div class="col-md-5 col-sm-7 col-xs-24">
           <img src="projects/rotation_equi/rep.png" width="450" " alt="">
       </div>
       <div class="col-md-1"></div>
       <div class="col-md-16">
           <h2>On the Universality of Rotation Equivariant Point Cloud Networks</h2>
           <p>
             Nadav Dym, Haggai Maron<br>
             <i> International Conference on Learning Representations (ICLR) 2021</i> <br>
           </p>
           <a class="btn btn-default abstract" ptitle="Learning functions on point clouds has applications in many fields, including computer vision, computer graphics, physics, and chemistry. Recently, there has been a growing interest in neural architectures that are invariant or equivariant to all three shape-preserving transformations of point clouds: translation, rotation, and permutation.
In this paper, we present a first study of the approximation power of these architectures. We first derive two sufficient conditions for an equivariant architecture to have the universal approximation property, based on a novel characterization of the space of equivariant polynomials. We then use these conditions to show that two recently suggested models are universal, and for devising two other novel universal architectures."> Abstract</a>
           <a href="https://arxiv.org/pdf/2010.02449" class="btn btn-default">Paper </a>
       </div>
</div><!-- end of row -->

<!--Open problems -->
   <div class="row" id="templatemo_publications_LargeScaleBD">
       <div class="col-md-1"></div>
       <div class="col-md-5 col-sm-7 col-xs-24">
           <img src="projects/AuxiLearn/framework.png" width="450" " alt="">
       </div>
       <div class="col-md-1"></div>
       <div class="col-md-16">
           <h2>Auxiliary Learning by Implicit Differentiation</h2>
           <p>
             Aviv Navon*, Idan Achituve*, Haggai Maron, Gal Chechik**, Ethan Fetaya** (*/** equal contribution)<br>
           <i>International Conference on Learning Representations (ICLR) 2021</i> <br>
           </p>
           <a class="btn btn-default abstract" ptitle="Training with multiple auxiliary tasks is a common practice used in deep learning for improving the performance on the main task of interest. Two main challenges arise in this multi-task learning setting: (i) Designing useful auxiliary tasks; and (ii) Combining auxiliary tasks into a single coherent loss. We propose a novel framework, \textit{AuxiLearn}, that targets both challenges, based on implicit differentiation. First, when useful auxiliaries are known, we propose learning a network that combines all losses into a single coherent objective function. This network can learn \textit{non-linear} interactions between auxiliary tasks. Second, when no useful auxiliary task is known, we describe how to learn a network that generates a meaningful, novel auxiliary task. We evaluate AuxiLearn in a series of tasks and domains, including image segmentation and learning with attributes. We find that AuxiLearn consistently improves accuracy compared with competing methods."> Abstract</a>
           <a href="https://arxiv.org/abs/2007.02693" class="btn btn-default">Paper </a>
           <a href="https://github.com/AvivNavon/AuxiLearn" class="btn btn-default">GitHub</a>


       </div>
</div><!-- end of row -->




</div>
<!--Open problems -->
<div class="row" id="templatemo_publications_LargeScaleBD">
    <div class="col-md-1"></div>
    <div class="col-md-5 col-sm-7 col-xs-24">
        <img src="projects/DA_3D_SSL/img.png" width="450" " alt="">
    </div>
    <div class="col-md-1"></div>
    <div class="col-md-16">
        <h2>Self-Supervised Learning for Domain Adaptation on Point-Clouds</h2>
        <p>
          Idan Achituve, Haggai Maron, Gal Chechik<br>
        <i>Winter Conference on Applications of Computer Vision (WACV), 2021</i> <br>
        </p>
        <a class="btn btn-default abstract" ptitle="
Abstract. Self-supervised learning (SSL) allows to learn useful repre- sentations from unlabeled data and has been applied effectively for do- main adaptation (DA) on images. It is still unknown if and how it can be leveraged for domain adaptation for 3D perception. Here we describe the first study of SSL for DA on point-clouds. We introduce a new pretext task, Region Reconstruction, motivated by the deformations encountered in sim-to-real transformation. We also demonstrate how it can be com- bined with a training procedure motivated by the MixUp method. Evaluations on six domain adaptations across synthetic and real furniture data, demonstrate large improvement over previous work."> Abstract</a>
        <a href="https://arxiv.org/pdf/2003.12641.pdf" class="btn btn-default">Paper </a>
        <a href="https://github.com/idanachi/RegRec_and_PCM" class="btn btn-default">GitHub </a>




    </div>
</div><!-- end of row -->






      </div>
      <!--Open problems -->
         <div class="row" id="templatemo_publications_LargeScaleBD">
             <div class="col-md-1"></div>
             <div class="col-md-5 col-sm-7 col-xs-24">
                 <img src="projects/set2graph/img.png" width="450" " alt="">
             </div>
             <div class="col-md-1"></div>
             <div class="col-md-16">
                 <h2>Set2Graph: Learning Graphs From Sets</h2>
                 <p>
                   Hadar Serviansky, Nimrod Segol, Jonathan Shlomi, Kyle Cranmer, Eilam Gross, Haggai Maron, Yaron Lipman<br>
                   <i> 34th Annual Conference on Neural Information Processing Systems (NeurIPS 2020) </i> <br>
                 </p>
                 <a class="btn btn-default abstract" ptitle="Many problems in machine learning (ML) can be cast as learning functions from sets to graphs, or more generally to hypergraphs; in short, Set2Graph functions. Examples include clustering, learning vertex and edge features on graphs, and learning triplet data in a collection. Current neural network models that approximate Set2Graph functions come from two main ML sub-fields: equivariant learning, and similarity learning. Equivariant models would be in general computationally challenging or even infeasible, while similarity learning models can be shown to have limited expressive power. In this paper we suggest a neural network model family for learning Set2Graph functions that is both practical and of maximal expressive power (universal), that is, can approximate arbitrary continuous Set2Graph functions over compact sets. Testing our models on different machine learning tasks, including an application to particle physics, we find them favorable to existing baselines."> Abstract</a>
                 <a href="https://arxiv.org/abs/2002.08772" class="btn btn-default">Paper </a>
                 <a href="https://github.com/hadarser/SetToGraphPaper" class="btn btn-default">Code </a>

             </div>
      </div><!-- end of row -->



      </div>
   <!--Open problems -->
      <div class="row" id="templatemo_publications_LargeScaleBD">
          <div class="col-md-1"></div>
          <div class="col-md-5 col-sm-7 col-xs-24">
              <img src="projects/DSS/img.png" width="450" " alt="">
          </div>
          <div class="col-md-1"></div>
          <div class="col-md-16">
              <h2>On Learning Sets of Symmetric Elements</h2>
              <p>
                Haggai Maron, Or Litany, Gal Chechik, Ethan Fetaya<br>
              <i>International Conference on Machine Learning (ICML) 2020</i> <br>
              </p>
              <p style="color:red;">ICML 2020 outstanding paper award</p>
              <a class="btn btn-default abstract" ptitle="Learning from unordered sets is a fundamental learning setup, which is attracting increasing attention. Research in this area has focused on the case where elements of the set are represented by feature vectors, and far less emphasis has been given to the common case where set elements themselves adhere to certain symmetries. That case is relevant to numerous applications, from deblurring image bursts to multi-view 3D shape recognition and reconstruction. In this paper, we present a principled approach to learning sets of general symmetric elements. We first characterize the space of linear layers that are equivariant both to element reordering and to the inherent symmetries of elements, like translation in the case of images. We further show that networks that are composed of these layers, called Deep Sets for Symmetric elements layers (DSS), are universal approximators of both invariant and equivariant functions. DSS layers are also straightforward to implement. Finally, we show that they improve over existing set-learning architectures in a series of experiments with images, graphs, and point-clouds"> Abstract</a>
              <a href="https://arxiv.org/pdf/2002.08599" class="btn btn-default">Paper </a>
              <a href="https://github.com/Haggaim/On-Learning-Sets-of-Symmetric-Elements" class="btn btn-default">Code</a>
              <a href="https://icml.cc/virtual/2020/poster/6022" class="btn btn-default">Video</a>
              <a href="projects/DSS/DSS_slides.pdf" class="btn btn-default">Slides</a>
              <a href="https://aihub.org/2020/08/20/interview-with-haggai-maron-icml2020-award-winner/" class="btn btn-default">Interview</a>
          </div>
  </div><!-- end of row -->



      </div>
   <!--Open problems -->
      <div class="row" id="templatemo_publications_LargeScaleBD">
          <div class="col-md-1"></div>
          <div class="col-md-5 col-sm-7 col-xs-24">
              <img src="projects/GNN_AMG/img.png" width="450" " alt="">
          </div>
          <div class="col-md-1"></div>
          <div class="col-md-16">
              <h2>Learning Algebraic Multigrid Using Graph Neural Networks</h2>
              <p>
              Ilay Luz, Meirav Galun, Haggai Maron, Ronen Basri, Irad Yavneh<br>
              <i>International Conference on Machine Learning (ICML) 2020</i> <br>
              </p>
              <a class="btn btn-default abstract" ptitle="Efficient numerical solvers for sparse linear systems are crucial in science and engineering. One of the fastest methods for solving large-scale sparse linear systems is algebraic multigrid (AMG). The main challenge in the construction of AMG algorithms is the selection of the prolongation operator--a problem-dependent sparse matrix which governs the multiscale hierarchy of the solver and is critical to its efficiency. Over many years, numerous methods have been developed for this task, and yet there is no known single right answer except in very special cases. Here we propose a framework for learning AMG prolongation operators for linear systems with sparse symmetric positive (semi-) definite matrices. We train a single graph neural network to learn a mapping from an entire class of such matrices to prolongation operators, using an efficient unsupervised loss function. Experiments on a broad class of problems demonstrate improved convergence rates compared to classical AMG, demonstrating the potential utility of neural networks for developing sparse system solvers."> Abstract</a>
              <a href="https://arxiv.org/pdf/2003.05744" class="btn btn-default">Paper </a>
              <a href="https://icml.cc/virtual/2020/poster/6369" class="btn btn-default">Video+Slides</a>
              <a href="https://github.com/ilayluz/learning-amg" class="btn btn-default">Code</a>
          </div>
  </div><!-- end of row -->









        </div>
     <!--Open problems -->
        <div class="row" id="templatemo_publications_LargeScaleBD">
            <div class="col-md-1"></div>
            <div class="col-md-5 col-sm-7 col-xs-24">
                <img src="projects/open_problems_igns/open_problems.png" width="450" " alt="">
            </div>
            <div class="col-md-1"></div>
            <div class="col-md-16">
                <h2>Open Problems: Approximation Power of Invariant Graph Networks</h2>
                <p>
                Haggai Maron, Heli Ben-Hamu, Yaron Lipman<br>
                <i>  NeurIPS 2019 Graph Representation Learning Workshop</i> <br>
                </p>
                <a class="btn btn-default abstract" ptitle="Learning graph data is of huge interest to the machine learning community. Recently, graph neural network models motivated by algebraic invariance and equivariance principles have been proposed (Ravanbakhsh et al., 2017; Kondor et al., 2018; Maron et al., 2019b). These models were shown to be universal (Maron et al., 2019c; Keriven and Peyré, 2019), in contrast to the popular message passing models Xu et al. (2019); Morris et al. (2018). In this note we formulate several open problems aiming at characterizing the trade-off between expressive power and complexity of these models."> Abstract</a>
                <a href="projects/open_problems_igns/Open Problems Approximation Power of InvariantGraph Networks.pdf" class="btn btn-default">Paper </a>
                <a href="projects/open_problems_igns/NeurIPS_graph_representation_learning_workshop.pdf" class="btn btn-default">Slides </a>
                <a href="https://slideslive.com/38921870/graph-representation-learning-1" class="btn btn-default">Talk (go to 1:15:00) </a>
            </div>
    </div><!-- end of row -->

  </div>
   <!--Deep and Convex -->
      <div class="row" id="templatemo_publications_LargeScaleBD">
          <div class="col-md-1"></div>
          <div class="col-md-5 col-sm-7 col-xs-24">
              <img src="projects/phd_thesis/image.png" width="450" " alt="">
          </div>
          <div class="col-md-1"></div>
          <div class="col-md-16">
              <h2>Ph.D. Thesis</h2>
              <p>
              Haggai Maron<br>
              <i> Weizmann Institute of Science, 2019 </i> <br>
              </p>
              <a class="btn btn-default abstract" ptitle="This dissertation summarizes the main results obtained during my Ph.D. studies at the Weizmann Institute of Science under the guidance of Professor Yaron Lipman. Two fundamental problems in shape analysis were considered: (1) how to apply deep learning techniques to irregular data and (2) how to compute meaningful maps between shapes. My work has resulted in several novel methods for applying deep learning to surfaces, point clouds (i.e., finite subsets of the Euclidean space), graphs and hyper-graphs as well as new efficient techniques to solve relaxations of well-known matching problems. The report discusses these two problems, surveys the suggested solutions and points out several directions for future work, including a promising direction that combines both problems."> Abstract</a>
              <a href="projects/phd_thesis/haggai_maron_phd_thesis.pdf" class="btn btn-default">Paper </a>

          </div>
  </div><!-- end of row -->






		</div>
     <!--Deep and Convex -->
        <div class="row" id="templatemo_publications_LargeScaleBD">
            <div class="col-md-1"></div>
            <div class="col-md-5 col-sm-7 col-xs-24">
                <img src="projects/SIGGRAPH_DC/teaser.jpg" width="450" " alt="">
            </div>
            <div class="col-md-1"></div>
            <div class="col-md-16">
                <h2>Deep and Convex Shape Analysis</h2>
                <p>
                Haggai Maron<br>
                <i> SIGGRAPH 2019 Doctoral Consortium </i> <br>
                </p>
                <a class="btn btn-default abstract" ptitle="In this paper, I review the main results obtained during my Ph.D. studies at the Weizmann Institute of Science under the guidance of Professor Yaron Lipman. Two fundamental problems in shape analysis were considered: (1) how to apply deep learning techniques to geometric objects and (2) how to compute meaningful maps between shapes. My work has resulted in several novel methods for applying deep learning to surfaces, point clouds, and hyper-graphs as well as new efficient techniques to solve relaxations of wellknown matching problems. The paper discusses these two problems, surveys the suggested solutions and points out several directions for future work, including a promising direction that combines both problems."> Abstract</a>
                <a href="projects/SIGGRAPH_DC/SIGGRAPH_doctoral_consortium.pdf" class="btn btn-default">Paper </a>                                <a href="projects/SIGGRAPH_DC/poster.pdf" class="btn btn-default">Poster </a>

            </div>
    </div><!-- end of row -->

 <!--provably powerful -->
        <div class="row" id="templatemo_publications_LargeScaleBD">
            <div class="col-md-1"></div>
            <div class="col-md-5 col-sm-7 col-xs-24">
                <img src="projects/powerful_graph/2019_powerful_gnn_.png" alt="">
            </div>
            <div class="col-md-1"></div>
            <div class="col-md-16">
                <h2>Provably Powerful Graph Networks	</h2>
                <p>
                Haggai Maron*, Heli Ben-Hamu*, Hadar Serviansky*, Yaron Lipman (*equal contribution)<br>
                <i> 33rd Annual Conference on Neural Information Processing Systems (NeurIPS 2019) </i> <br>
                </p>
                <a class="btn btn-default abstract" ptitle="Recently, the Weisfeiler-Lehman (WL) graph isomorphism test was used to measure the expressive power of graph neural networks (GNN). It was shown that the popular message passing GNN cannot distinguish between graphs that are indistinguishable by the 1-WL test (Morris et al., 2018; Xu et al., 2019). Unfortunately, many simple instances of graphs are indistinguishable by the 1-WL test. In search for more expressive graph learning models we build upon the recent k-order invariant and equivariant graph neural networks (Maron et al., 2019a,b) and present two results: First, we show that such k-order networks can distinguish between non-isomorpic graphs as good as the k-WL tests, which are provably stronger than the 1-WL test for k > 2. This makes these models strictly stronger than message passing models. Unfortunately, the higher expressiveness of these models comes with a computational cost of processing high order tensors. Second, setting our goal at building a provably stronger, simple and scalable model we show that a reduced 2-order network containing just scaled identity operator, augmented with a single quadratic operation (matrix multiplication) has a provable 3-WL expressive power. Differently put, we suggest a simple model that interleaves applications of standard Multilayer-Perceptron (MLP) applied to the feature dimension and matrix multiplication. We validate this model by presenting state of the art results on popular graph classification and regression tasks. To the best of our knowledge, this is the first practical invariant/equivariant model with guaranteed 3-WL expressiveness, strictly stronger than message passing models. "> Abstract</a>
                <a href="https://arxiv.org/abs/1905.11136" class="btn btn-default">Arxiv </a>
                <a href="https://github.com/hadarser/ProvablyPowerfulGraphNetworks" class="btn btn-default">  GitHub (TensorFlow) </a>
                <a href="https://github.com/hadarser/ProvablyPowerfulGraphNetworks_torch" class="btn btn-default">  GitHub (PyTorch)</a>
                <a href="http://irregulardeep.org/How-expressive-are-Invariant-Graph-Networks-(2-2)/" class="btn btn-default">  Blog post </a>
                <a href="projects/powerful_graph/Provably_Powerful_Graph_Networks___Poster.pdf" class="btn btn-default">Poster </a>




            </div>
        </div><!-- end of row -->

     <!--levelsets -->
        <div class="row" id="templatemo_publications_LargeScaleBD">
            <div class="col-md-1"></div>
            <div class="col-md-5 col-sm-7 col-xs-24">
                <img src="projects/level_sets/2019_neural_levelsets.png" alt="">
            </div>
            <div class="col-md-1"></div>
            <div class="col-md-16">
                <h2>Controlling Neural Level Sets	</h2>
                <p>
                Matan Atzmon, Niv Haim, Lior Yariv, Ofer Israelov, Haggai Maron, Yaron Lipman <br>
                <i> 33rd Annual Conference on Neural Information Processing Systems (NeurIPS 2019) </i> <br>
                </p>
                <a class="btn btn-default abstract" ptitle="The level sets of neural networks represent fundamental properties such as decision boundaries of classifiers and are used to model non-linear manifold data such as curves and surfaces. Thus, methods for controlling the neural level sets could find many applications in machine learning. In this paper we present a simple and scalable approach to directly control level sets of a deep neural network. Our method consists of two parts: (i) sampling of the neural level sets, and (ii) relating the samples’ positions to the network parameters. The latter is achieved by a sample network that is constructed by adding a single fixed linear layer to the original network. In turn, the sample network can be used to incorporate the level set samples into a loss function of interest. We have tested our method on three different learning tasks:  raining networks robust to adversarial attacks, improving generalization to unseen data, and curve and surface reconstruction from point clouds. Notably, we increase robust accuracy to the level of standard classification accuracy in off-the-shelf networks, improving it by 2% in MNIST and 27% in CIFAR10 compared to state-of-the-art methods. For surface reconstruction, we produce high fidelity surfaces directly from raw 3D point clouds."> Abstract</a>
                <a href="https://arxiv.org/abs/1905.11911" class="btn btn-default">Arxiv </a>
                <a href="https://github.com/matanatz/ControllingNeuralLevelsets" class="btn btn-default">Code </a>
                <a href="https://github.com/matanatz/ControllingNeuralLevelsets/blob/master/Controlling_Neural_Level_Sets_Poster.pdf" class="btn btn-default">Poster </a>
            </div>
        </div><!-- end of row -->

<!--general covers -->
        <div class="row" id="templatemo_publications_LargeScaleBD">
            <div class="col-md-1"></div>
            <div class="col-md-5 col-sm-7 col-xs-24">
                <img src="projects/general_covers/web_img.png" alt="">
            </div>
            <div class="col-md-1"></div>
            <div class="col-md-16">
                <h2>Surface Networks via General Covers</h2>
                <p>
                Niv Haim*, Nimrod Segol*, Heli Ben-Hamu, Haggai Maron, Yaron Lipman (*equal contribution)<br>
                <i>International Conference on Computer Vision (ICCV) 2019 </i> <br>
                </p>
                <a class="btn btn-default abstract" ptitle="Developing deep learning techniques for geometric data is an active and fruitful research area. This paper tackles the problem of sphere-type surface learning by developing a novel surface-to-image representation. Using this representation we are able to quickly adapt successful CNN models to the surface setting. The surface-image representation is based on a covering map from the image domain to the surface. Namely, the map wraps around the surface several times, making sure that every part of the surface is well represented in the image. Differently from previous surface-to-image representations we provide a low distortion coverage of all surface parts in a single image. We have used the surface-to-image representation to apply standard CNN models to the problem of semantic shape segmentation and shape retrieval, achieving state of the art results in both."> Abstract</a>
                <a href="https://arxiv.org/pdf/1812.10705.pdf" class="btn btn-default">Arxiv </a>
        </div>
        </div><!-- end of row -->


    <!--universality -->
        <div class="row" id="templatemo_publications_LargeScaleBD">
            <div class="col-md-1"></div>
            <div class="col-md-5 col-sm-7 col-xs-24">
                <img src="projects/universality/rep2.png" alt="">
            </div>
            <div class="col-md-1"></div>
            <div class="col-md-16">
                <h2>On the Universality of Invariant Networks</h2>
                <p>
                Haggai Maron, Ethan Fetaya, Nimrod Segol, Yaron Lipman<br>
                <i> International Conference on Machine Learning (ICML) 2019 </i> <br>
                </p>
                <a class="btn btn-default abstract" ptitle="Constraining linear layers in neural networks to respect symmetry transformations from a group $G$ is a common design principle for invariant networks that has found many applications in machine learning. In this paper, we consider a fundamental question that has received little attention to date: Can these networks approximate any (continuous) invariant function? 	We tackle the rather general case where $G\leq S_n$ (an arbitrary subgroup of the symmetric group) that acts on $\R^n$ by permuting coordinates. This setting includes several recent popular invariant networks. We present two main results: First, $G$-invariant networks are universal if high-order tensors are allowed. Second, there are groups $G$ for which higher-order tensors are unavoidable for obtaining universality. $G$-invariant networks consisting of only first-order tensors are of special interest due to their practical value. We conclude the paper by proving a necessary condition for the universality of $G$-invariant networks that incorporate only first-order tensors."> Abstract</a>
                <a href="https://arxiv.org/abs/1901.09342" class="btn btn-default">Arxiv </a>
                <a href="projects/universality/poster.pdf" class="btn btn-default">Poster </a>
                <a href="https://www.videoken.com/embed/wLHp27J0CyQ?tocitem=22" class="btn btn-default">Video</a>
                <a href="http://irregulardeep.org/How-expressive-are-Invariant-Graph-Networks-(2-2)/" class="btn btn-default">Blog post</a>


            </div>
        </div><!-- end of row -->

    <!--GRAPH -->
        <div class="row" id="templatemo_publications_LargeScaleBD">
            <div class="col-md-1"></div>
            <div class="col-md-5 col-sm-7 col-xs-24">
                <img src="projects/Invariant_and_equivariant_graph_networks/graph.png" alt="image 1">
            </div>
            <div class="col-md-1"></div>
            <div class="col-md-16">
                <h2>Invariant and Equivariant Graph Networks</h2>
                <p>
                Haggai Maron, Heli Ben-Hamu, Nadav Shamir and Yaron Lipman<br>
                <i>International Conference on Learning Representations (ICLR) 2019 </i> <br>
                </p>
                <a class="btn btn-default abstract" ptitle="Invariant and equivariant networks have been successfully used for learning images, sets, point clouds, and graphs. A basic  challenge in developing such networks is finding the maximal collection of invariant and equivariant linear layers. Although this question is answered for the first three examples (for popular transformations, at-least), a full characterization of invariant and equivariant linear layers for graphs is not known.   In this paper, we provide a characterization of all permutation invariant and equivariant linear layers for (hyper-)graph data, and show that their dimension, in case of edge-value graph data, is 2 and 15, respectively. More generally, for graph data defined on k-tuples of nodes, the dimension is the k-th and 2k-th Bell numbers. Orthogonal bases for the layers are computed, including generalization to multi-graph data. The constant number of basis elements and their characteristics allow successfully applying the networks to different size graphs. From the theoretical point of view, our results generalize and unify recent advancement in equivariant deep learning.  Applying these new linear layers in a simple deep neural network framework is shown to achieve comparable results to state-of-the-art and to have better expressivity than previous invariant and equivariant bases."> Abstract</a>
                <a href="https://arxiv.org/pdf/1812.09902.pdf" class="btn btn-default">  Arxiv </a>
                <a href="https://github.com/Haggaim/InvariantGraphNetworks" class="btn btn-default">GitHub</a>
                <a href="projects/Invariant_and_equivariant_graph_networks/poster.pdf" class="btn btn-default">  Poster </a>
                <a href="http://irregulardeep.org/An-introduction-to-Invariant-Graph-Networks-(1-2)/" class="btn btn-default">  Blog post </a>

        </div>
        </div><!-- end of row -->


    <!-- Yamkush -->
		<div class="row" id="templatemo_publications_LargeScaleBD">
            <div class="col-md-1"></div>
            <div class="col-md-5 col-sm-7 col-xs-24">
                <img src="projects/lifted_sinkhorn/rep.png" alt="image 1">
            </div>
            <div class="col-md-1"></div>
            <div class="col-md-16">
                <h2>Sinkhorn Algorithm for Lifted Assignment Problems</h2>
				<p>
				Yam Kushinsky, Haggai Maron, Nadav Dym and Yaron Lipman<br>
				<i>SIAM Journal on Imaging Sciences, 2019 </i> <br>
				</p>
				<a class="btn btn-default abstract" ptitle="Sinkhorn Algorithm for Lifted Assignment Problems" abstract="Recently, Sinkhorn&#39;s algorithm was applied for solving regularized linear programs emerging from optimal transport very efficiently. Sinkhorn&#39;s algorithm is an efficient method of projecting a positive matrix onto the polytope of doubly-stochastic matrices. It is based on alternating closed-form Bregman projections on the larger polytopes of row-stochastic and column-stochastic matrices. In this paper we generalize the Sinkhorn projection algorithm to higher dimensional polytopes originated from well-known lifted linear program relaxations of the Markov Random Field (MRF) energy minimization problem and the Quadratic Assignment Problem (QAP). We derive a closed-form projection on one-sided local polytopes which can be seen as a high-dimensional, generalized version of the row/column-stochastic polytopes. We then use these projections to devise a provably convergent algorithm to solve regularized linear program relaxations of MRF and QAP. Furthermore, as the regularization is decreased both the solution and the optimal energy value converge to that of the respective linear program. The resulting algorithm is considerably more scalable than standard linear solvers and is able to solve significantly larger linear programs. "> Abstract</a>
				<a href="https://arxiv.org/abs/1707.07285" class="btn btn-default">  Arxiv </a>
				<!--<a href="index.html" class="btn btn-default">Code (coming soon)</a>-->
		</div>
        </div><!-- end of row -->


<!--NIPS -->
        <div class="row" id="templatemo_publications_LargeScaleBD">
            <div class="col-md-1"></div>
            <div class="col-md-5 col-sm-7 col-xs-24">
                <img src="projects/concave/rep.png" alt="image 1">
            </div>
            <div class="col-md-1"></div>
            <div class="col-md-16">
                <h2>(Probably) Concave Graph Matching</h2>
                <p>
                Haggai Maron and Yaron Lipman<br>
                <i>32nd Annual Conference on Neural Information Processing Systems (NeurIPS 2018)</i> <br>
                <p style="color:red;">spotlight presentation (3.5% acceptance rate)</p>

                </p>
                <a class="btn btn-default abstract" ptitle="In this paper we address the graph matching problem. Following the recent works of \cite{zaslavskiy2009path,Vestner2017} we analyze and generalize the idea of concave relaxations. We introduce the concepts of conditionally concave and probably conditionally concave energies on polytopes and show that they encapsulate many instances of the graph matching problem, including matching Euclidean graphs and graphs on surfaces. We further prove that local minima of probably conditionally concave energies on general matching polytopes (e.g., doubly stochastic) are with high probability extreme points of the matching polytope (e.g., permutations)."> Abstract</a>
                <a href="https://arxiv.org/pdf/1807.09722.pdf" class="btn btn-default">  Arxiv </a>
                <a href="projects/concave/poster.pdf" class="btn btn-default">  Poster </a>
                <a href="https://youtu.be/ZsN1__FFZlk" class="btn btn-default">  Short Video </a>
				<a href="https://github.com/Haggaim/ConcaveGraphMatching" class="btn btn-default">GitHub</a>
        </div>
        </div><!-- end of row -->



        <!--Heli -->
        <div class="row" id="templatemo_publications_LargeScaleBD">
            <div class="col-md-1"></div>
            <div class="col-md-5 col-sm-7 col-xs-24">
                <img src="projects/multichart/rep.png" alt="image 1">
            </div>
            <div class="col-md-1"></div>
            <div class="col-md-16">
                <h2>Multi-chart Generative Surface Modeling</h2>
                <p>
                Heli Ben-Hamu, Haggai Maron, Itay Kezurer, Gal Avineri and Yaron Lipman<br>
                <i>ACM SIGGRAPH Asia 2018</i> <br>
                </p>
                <a class="btn btn-default abstract" ptitle="new image-like (ie, tensor) data representation for genus-zero 3D shapes is devised. It is based on the observation that complicated shapes can be well represented by multiple parameterizations (charts), each focusing on a different part of the shape. The new tensor data representation is used as input to Generative Adversarial Networks for the task of 3D shape generation. The 3D shape tensor representation is based on a multi-chart structure that enjoys a shape covering property and scale-translation rigidity. Scale-translation rigidity facilitates high quality 3D shape learning and guarantees unique reconstruction. The multi-chart structure uses as input a dataset of 3D shapes (with arbitrary connectivity) and a sparse correspondence between them. The output of our algorithm is a generative model that learns the shape distribution and is able to generate novel shapes, interpolate shapes, and explore the generated shape space. The effectiveness of the method is demonstrated for the task of anatomic shape generation including human body and bone (teeth) shape generation. "> Abstract</a>
                <a href="https://arxiv.org/pdf/1806.02143.pdf" class="btn btn-default">  Arxiv </a>
                <a href="https://github.com/helibenhamu/multichart3dgans" class="btn btn-default">GitHub</a>
        </div>
        </div><!-- end of row -->




        <!--PCNN -->
        <div class="row" id="templatemo_publications_LargeScaleBD">
            <div class="col-md-1"></div>
            <div class="col-md-5 col-sm-7 col-xs-24">
                <img src="projects/PCNN/rep.png" alt="image 1">
            </div>
            <div class="col-md-1"></div>
            <div class="col-md-16">
                <h2>Point Convolutional Neural Networks by Extension Operators</h2>
                <p>
                Matan Atzmon*, Haggai Maron* and Yaron Lipman (*equal contribution)<br>
                <i>ACM SIGGRAPH 2018</i> <br>
                </p>
                <a class="btn btn-default abstract" ptitle="This paper presents Point Convolutional Neural Networks (PCNN): a novel framework for applying convolutional neural networks to point clouds. The framework consists of two operators: extension and restriction, mapping point cloud functions to volumetric functions and vise-versa. A point cloud convolution is defined by pull-back of the Euclidean volumetric convolution via an extension-restriction mechanism. The point cloud convolution is computationally efficient, invariant to the order of points in the point cloud, robust to different samplings and varying densities, and translation invariant, that is the same convolution kernel is used at all points. PCNN generalizes image CNNs and allows readily adapting their architectures to the point cloud setting. Evaluation of PCNN on three central point cloud learning benchmarks convincingly outperform competing point cloud learning methods, and the vast majority of methods working with more informative shape representations such as surfaces and/or normals"> Abstract</a>
                <a href="https://arxiv.org/abs/1803.10091" class="btn btn-default">  Arxiv </a>
                <a href="https://github.com/matanatz/pcnn" class="btn btn-default">GitHub</a>
                <a href="projects/PCNN/pointConv_sigraph_final_pdf.pdf" class="btn btn-default">Slides</a>

        </div>
        </div><!-- end of row -->

		<!-- DSPP -->
		<div class="row" id="templatemo_publications_LargeScaleBD">
            <div class="col-md-1"></div>
            <div class="col-md-5 col-sm-7 col-xs-24">
                <img src="projects/DSPP/rep.png" alt="image 1">
            </div>
            <div class="col-md-1"></div>
            <div class="col-md-16">
                <h2>DS++: A Flexible, Scalable and Provably Tight Relaxation for Matching Problems</h2>
				<p>
				Nadav Dym*, Haggai Maron* and Yaron Lipman (*equal contribution)<br>
				<i>ACM SIGGRAPH ASIA 2017</i> <br>
				</p>
				<a class="btn btn-default abstract" ptitle="DS++: A Flexible, Scalable and Provably Tight Relaxation for Matching Problems" abstract="Correspondence problems are often modelled as quadratic optimization problems over permutations. Common scalable methods for approximating solutions of these NP-hard problems are the spectral relaxation for non-convex energies and the doubly stochastic (DS) relaxation for convex energies. Lately, it has been demonstrated that semidefinite programming relaxations can have considerably improved accuracy at the price of a much higher computational cost.We present a convex quadratic programming relaxation which is provably stronger than both DS and spectral relaxations, with the same scalability as the DS relaxation. The derivation of the relaxation also naturally suggests a projection method for achieving meaningful integer solutions which  improves upon the standard closest-permutation projection. Our method can be easily extended to optimization over doubly stochastic matrices, partial or injective matching, and problems with additional linear constraints. We employ recent advances in optimization of linear-assignment type problems to achieve an efficient algorithm for solving the convex relaxation.We present experiments indicating that our method is  more accurate than local minimization or competing relaxations for non-convex problems. We successfully apply our algorithm to shape matching and to the problem of ordering images in a grid, obtaining results which compare favorably with state of the art methods. We believe our results indicate that our method should be considered the method of choice for quadratic optimization over permutations  ">Abstract</a>
				<a href="https://arxiv.org/abs/1705.06148" class="btn btn-default">  Arxiv </a>
				<a href="https://github.com/Haggaim/DSPP" class="btn btn-default">GitHub</a>
                <a href="projects/DSPP/DSPP_ppt_sig_asia.pdf" class="btn btn-default">Slides</a>

		</div>
        </div><!-- end of row -->





		<div class="row" id="templatemo_publications_LargeScaleBD">
            <div class="col-md-1"></div>
            <div class="col-md-5 col-sm-7 col-xs-24">
                <img src="projects/geometry_learning/rep.png" alt="image 1">
            </div>
            <div class="col-md-1"></div>
            <div class="col-md-16">
                <h2>Convolutional Neural Networks on Surfaces via Seamless Toric Covers</h2>
				<p>
				Haggai Maron, Meirav Galun, Noam Aigerman, Miri Trope, Nadav Dym, Ersin Yumer, Vladimir G. Kim and Yaron Lipman<br>
				<i>ACM SIGGRAPH 2017</i> <br>
				</p>
				<a class="btn btn-default abstract" ptitle="Convolutional Neural Networks on Surfaces via Seamless Toric Covers" abstract="The recent success of convolutional neural networks (CNNs) for image processing tasks is inspiring research efforts attempting to achieve similar success for geometric tasks. One of the main challenges in applying CNNs to surfaces is defining a natural convolution operator on surfaces. In this paper we present a method for applying deep learning to spheretype shapes using a global seamless parameterization to a planar flat-torus, for which the convolution operator is well defined. As a result, the standard deep learning framework can be readily applied for learning semantic, highlevel properties of the shape. An indication of our success in bridging the gap between images and surfaces is the fact that our algorithm succeeds in learning semantic information from an input of raw low-dimensional feature vectors. We demonstrate the usefulness of our approach by presenting two applications: human body segmentation, and automatic landmark detection on anatomical surfaces. We show that our algorithm compares favorably with competing geometric deep-learning algorithms for segmentation tasks, and is able to produce meaningful correspondences on anatomical surfaces where hand-crafted features are bound to fail. ">Abstract</a>
				<a href="projects/geometry_learning/paper_low_res.pdf" class="btn btn-default">Paper (low res)</a>
				<a href="https://github.com/Haggaim/ToricCNN" class="btn btn-default">GitHub</a>
                <a href="https://www.dropbox.com/sh/cnyccu3vtuhq1ii/AADgGIN6rKbvWzv0Sh-Kr417a?dl=0" class="btn btn-default">Data</a>
                <a href="projects/geometry_learning/GeometryLearning_siggraph.pdf" class="btn btn-default">Slides</a>
                <a href="https://dl.acm.org/ft_gateway.cfm?id=3073616&ftid=1918032" class="btn btn-default">Video</a>


		</div>
        </div><!-- end of row -->

		<div class="row" id="templatemo_publications_LargeScaleBD">
            <div class="col-md-1"></div>
            <div class="col-md-5 col-sm-7 col-xs-24">
                <img src="projects/point_registration/rep.png" alt="image 1">
            </div>
            <div class="col-md-1"></div>
            <div class="col-md-16">
                <h2>Point Registration via Efficient Convex Relaxation</h2>
				<p>
				Haggai Maron, Nadav Dym, Itay Kezurer, Shahar Kovalsky and Yaron Lipman<br>
				<i>ACM SIGGRAPH 2016 </i> <br>
				</p>
				<a class="btn btn-default abstract" ptitle="Point Registration via Efficient Convex Relaxation" abstract="Point cloud registration is a fundamental task in computer graphics and more specifically, in rigid and non-rigid shape matching. The rigid shape matching problem can be formulated as the problem of simultaneously aligning and labelling two point clouds in 3D so that they are as similar as possible. We name this problem the Procrustes matching (PM) problem. The non-rigid shape matching problem can be formulated as a PM problem in higher dimension using the functional maps method. High dimensional PM problems are difficult non-convex problems which currently can  only be solved locally using iterative closest point (ICP) algorithms or similar methods. So far, good initialization for the local algorithms was obtained by relying on user input. We introduce a novel and efficient convex SDP relaxation for the PM problem. We prove that for (generic) isometric or almost-isometric problems the algorithm returns a correct global solution of the problem. We show our algorithm gives state of the art results on popular shape matching datasets. We also show that our algorithm gives state of the art results for anatomical classification of shapes. Finally we demonstrate the successfulness of our method in aligning shape collections.">Abstract</a>
				<a href="projects/point_registration/PMSDP_final_light.pdf" class="btn btn-default">Paper (low res)</a>

				<a href="https://github.com/Haggaim/PM-SDP" class="btn btn-default">GitHub</a>
				<a href="projects/point_registration/PM-SIGGRAPH_site.pptx" class="btn btn-default">Slides</a>
                <a href="https://dl.acm.org/ft_gateway.cfm?id=2925913&ftid=1800661" class="btn btn-default">Video</a>

		</div>
        </div><!-- end of row -->

		<div class="row" id="templatemo_publications_LargeScaleBD">
            <div class="col-md-1"></div>
            <div class="col-md-5 col-sm-7 col-xs-24">
                <img src="projects/light_sesitive_display/rep2.png" width="100%" height="100%" alt="image 1">
            </div>
            <div class="col-md-1"></div>
            <div class="col-md-16">
                <h2>Passive Light and Viewpoint Sensitive Display of 3D Content</h2>
				<p>
				Anat Levin, Haggai Maron and Michal Yarom<br>
				<i>International Conference on Computational Photography (ICCP) 2016</i> <br>
				</p>
				<a class="btn btn-default abstract" ptitle="Passive Light and Viewpoint SensitiveDisplay of 3D Content" abstract="We present a 3D light-sensitive display. The display is capable of presenting simple opaque 3Dsurfaces without self occlusions, while reproducing both viewpoint-sensitive depth parallax and illumination-sensitive variations such as shadows and highlights. Our display is passive in the sense that it does not rely on illumination sensors and on-the-fly rendering of the image content. Rather, it consists of optical elements that produce light transport paths approximating those present in the real scene. Our display uses two layers of Spatial Light Modulators (SLMs) whose micron-sized elements allow us to digitally simulate thin optical surfaces with flexible shapes. We derive a simple content creation algorithm utilizing geometric optics tools to design optical surfaces that can mimic the ray transfer of target virtual 3D scenes. We demonstrate a possible implementation of a small prototype, and present a number of simple virtual 3D scenes. ">Abstract</a>
				<a href="projects/light_sesitive_display/LightSensitiveDisplayICCP.pdf" class="btn btn-default">Paper</a>
				<a href="projects/light_sesitive_display/LightSensitiveDisplayICCP_extended.pdf" class="btn btn-default">Paper+Supplementary</a>
		</div>
        </div><!-- end of row -->


</section><!-- end of templatemo_publications -->

<br>
<br>

<!--<script src="https://maps.googleapis.com/maps/api/js?v=3.exp&amp;sensor=false"></script> -->
<script src="js/jquery.min.js"></script>
<script src="js/jquery.scrollto.min.js"></script>
<script src="js/jquery.easing.min.js"></script>
<script src="js/bootstrap.min.js"></script>
<script src="js/jquery.lightbox.min.js"></script>
<script src="js/jquery.flexslider.js"></script>
<script src="js/jquery.singlePageNav.min.js"></script>
<script src="js/templatemo_script.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','../../www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-52088992-1', 'weizmann.ac.il');
  ga('require', 'linkid', 'linkid.html');
  ga('send', 'pageview');
</script>
</body>

<!-- Mirrored from www.wisdom.weizmann.ac.il/~shaharko/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 06 Apr 2016 11:56:56 GMT -->
</html>
